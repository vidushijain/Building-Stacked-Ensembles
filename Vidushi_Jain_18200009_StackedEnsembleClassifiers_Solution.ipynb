{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP47590: Advanced Machine Learning\n",
    "# Assignment 1: Building Stacked Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name(s): Vidushi Jain\n",
    "\n",
    "Student Number(s):18200009"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages Etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML, Image\n",
    "\n",
    "from TAS_Python_Utilities import data_viz\n",
    "from TAS_Python_Utilities import data_viz_target\n",
    "from TAS_Python_Utilities import visualize_tree\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "from random import randint\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from scipy.spatial import distance\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import ensemble\n",
    "from sklearn import linear_model\n",
    "from sklearn import neighbors\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import itertools\n",
    "\n",
    "%matplotlib inline\n",
    "#%qtconsole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define StackedEnsembleClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility function to create classifer objects based on a name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classifier(classifier_type, tree_min_samples_split = 20):\n",
    "\n",
    "    if classifier_type == \"svm\":\n",
    "        c = svm.SVC(probability=True)\n",
    "\n",
    "    elif classifier_type == \"logreg\":\n",
    "        c = linear_model.LogisticRegression(multi_class='ovr', solver='liblinear', max_iter=1000)\n",
    "\n",
    "    elif classifier_type == \"knn\":\n",
    "        c = neighbors.KNeighborsClassifier()\n",
    "\n",
    "    elif classifier_type == \"tree\":\n",
    "        c = tree.DecisionTreeClassifier(min_samples_split = tree_min_samples_split)\n",
    "\n",
    "    elif classifier_type == \"randomforest\":\n",
    "        c = ensemble.RandomForestClassifier()\n",
    "        \n",
    "    else:\n",
    "        c = linear_model.LogisticRegression(multi_class='ovr', solver='liblinear', max_iter=1000)\n",
    "    \n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StackedEnsembleClassifier class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new classifier which is based on the sckit-learn BaseEstimator and ClassifierMixin classes\n",
    "class StackedEnsembleClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    \"\"\"An ensemble classifier that uses heterogeneous models at the base layer and a aggregatnio model at the aggregation layer. A k-fold cross validation is used to gnerate training data for the stack layer model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    base_estimators: list \n",
    "        A list of the classifiers in the ase layer of the ensemble. Supported types are\n",
    "        - \"svm\" Support Vector Machine implemented by sklearn.svm.SVC\n",
    "        - \"logreg\" Logistic Regression implemented by sklearn.linear_models.LogisticRegression\n",
    "        - \"knn\" k Nearest Neighbour implemented by sklearn.neighbors.KNeighborsClassifier\n",
    "        - \"tree\" Decision Tree implemented by sklearn.tree.DecisionTreeClassifier\n",
    "        - \"randomforest\" RandomForest implemented by sklearn.tree.RandomForestClassifier    \n",
    "    classifier_duplicates: int, optional (default = 1)\n",
    "        How many instances of each classifier type listed in base_estimators is included in the ensemble\n",
    "    stack_layer_classifier: string, optional (default = \"logreg')\n",
    "        The classifier type used at the stack layer. The same classifier types as are supported at the base layer are supported        \n",
    "    training_folds: int, optional (default = 4)\n",
    "        How many folds will be used to generate the training set for the stacked layer\n",
    "        \n",
    "    Attributes\n",
    "    ----------\n",
    "    classes_ : array of shape = [n_classes] \n",
    "        The classes labels (single output problem).\n",
    "\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The default values for most base learners are used.\n",
    "\n",
    "    See also\n",
    "    --------\n",
    "    \n",
    "    ----------\n",
    "    .. [1]  van der Laan, M., Polley, E. & Hubbard, A. (2007). \n",
    "            Super Learner. Statistical Applications in Genetics \n",
    "            and Molecular Biology, 6(1) \n",
    "            doi:10.2202/1544-6115.1309\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from sklearn.datasets import load_iris\n",
    "    >>> from sklearn.model_selection import cross_val_score\n",
    "    >>> clf = StackedEnsembleClassifier()\n",
    "    >>> iris = load_iris()\n",
    "    >>> cross_val_score(clf, iris.data, iris.target, cv=10)\n",
    "\n",
    "    \"\"\"\n",
    "    # Constructor for the classifier object\n",
    "    def __init__(self, base_estimator_types = [\"svm\", \"logreg\", \"tree\"], base_estimator_duplicates = 8, stack_layer_classifier_type = \"logreg\"):\n",
    "        \"\"\"Setup a SuperLearner classifier .\n",
    "        Parameters\n",
    "        ----------\n",
    "        base_estimator_types: The types of classifiers to include at the base layer\n",
    "        base_estimator_duplicates: The number of duplicates of each type of classiifer to include\n",
    "        stack_layer_classifier_type: The type of classifier to include at the stack layer \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Nothing\n",
    "        \"\"\"     \n",
    "\n",
    "        # Initialise class variabels\n",
    "        self.base_estimator_types = base_estimator_types\n",
    "        self.base_estimator_type_list = list()\n",
    "        self.base_estimator_duplicates = base_estimator_duplicates\n",
    "        self.stack_layer_classifier_type = stack_layer_classifier_type\n",
    "\n",
    "    # The fit function to train a classifier\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Build a SuperLearner classifier from the training set (X, y).\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape = [n_samples, n_features]\n",
    "            The training input samples. \n",
    "        y : array-like, shape = [n_samples] \n",
    "            The target values (class labels) as integers or strings.\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "        \"\"\"    \n",
    "        \n",
    "        # Check that X and y have correct shape\n",
    "        X, y = check_X_y(X, y)\n",
    "        # Store the classes seen during fit\n",
    "        self.classes_ = unique_labels(y)\n",
    "        \n",
    "        ########################\n",
    "        # LEVEL 0\n",
    "        ########################\n",
    "        \n",
    "        # Set up the base classifeirs in the ensemble\n",
    "        self.classifiers_ = list()\n",
    "        \n",
    "        for i in range(0, self.base_estimator_duplicates):\n",
    "            for t in self.base_estimator_types:\n",
    "\n",
    "                self.base_estimator_type_list.append(t)      \n",
    "                c = create_classifier(t, tree_min_samples_split=math.ceil(len(X)*0.05))\n",
    "                self.classifiers_.append(c)\n",
    "        \n",
    "        # Store the number of classifers in the ensemble\n",
    "        self.n_estimators_ = len(self.classifiers_)\n",
    "\n",
    "        # Use all training data to train base classifiers\n",
    "        X_train = X\n",
    "        y_train = y\n",
    "        \n",
    "        # Set up empty arrays to hold stack layer training data\n",
    "        self.X_stack_train = None #(dtype = float)\n",
    "        self.y_stack_train = y_train\n",
    "          \n",
    "        # Train each base calssifier and generate the stack layer training dataset\n",
    "        for classifier in self.classifiers_:\n",
    "\n",
    "            # Extract a bootstrap sample\n",
    "            X_train_samp, y_train_samp = resample(X_train, y_train, replace=True)    \n",
    "            \n",
    "            # Train a base classifier\n",
    "            classifier.fit(X_train_samp, y_train_samp)\n",
    "            \n",
    "            # Make predictions for all instances in the training set\n",
    "            y_pred = classifier.predict_proba(X_train)\n",
    "\n",
    "            \n",
    "            # Append the predictions ot the stack layer traing set (a bit of hacking here!)\n",
    "            try:\n",
    "                self.X_stack_train = np.c_[self.X_stack_train, y_pred]                \n",
    "            except ValueError:\n",
    "                self.X_stack_train = y_pred\n",
    "      \n",
    "        ########################\n",
    "        # LEVEL 1\n",
    "        ########################\n",
    "        \n",
    "        # Create the stack layer classifier\n",
    "        self.stack_layer_classifier_ = create_classifier(self.stack_layer_classifier_type, tree_min_samples_split=math.ceil(len(X)*0.05))\n",
    "\n",
    "        # Train the stack layer using the newly created dataset\n",
    "        self.stack_layer_classifier_.fit(self.X_stack_train, self.y_stack_train)\n",
    "            \n",
    "        # Return the classifier\n",
    "        return self\n",
    "\n",
    "    # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels of the input samples X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like matrix of shape = [n_samples, n_features]\n",
    "            The input samples. \n",
    "        Returns\n",
    "        -------\n",
    "        p : array of shape = [n_samples, ].\n",
    "            The predicted class labels of the input samples. \n",
    "        \"\"\"\n",
    "        \n",
    "        # Check is fit had been called by confirming that the teamplates_ dictiponary has been set up\n",
    "        check_is_fitted(self, ['stack_layer_classifier_'])\n",
    "\n",
    "        # Check that the input features match the type and shape of the training features\n",
    "        X = check_array(X)\n",
    "   \n",
    "        X_stack_queries = None\n",
    "              \n",
    "        # Make a prediction with each base classifier and assemble the stack layer query\n",
    "        for classifier in self.classifiers_:\n",
    "            \n",
    "            y_pred = classifier.predict_proba(X)\n",
    "            \n",
    "            try:\n",
    "                X_stack_queries = np.c_[X_stack_queries, y_pred]\n",
    "            except ValueError:\n",
    "                X_stack_queries = y_pred\n",
    "        \n",
    "        # Return the prediction made by the stack layer classifier\n",
    "        return self.stack_layer_classifier_.predict(X_stack_queries)\n",
    "    \n",
    "    # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict class probabilities of the input samples X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like matrix of shape = [n_samples, n_features]\n",
    "            The input samples. \n",
    "        Returns\n",
    "        -------\n",
    "        p : array of shape = [n_samples, n_labels].\n",
    "            The predicted class label probabilities of the input samples. \n",
    "        \"\"\"\n",
    "        # Check is fit had been called by confirming that the teamplates_ dictiponary has been set up\n",
    "        check_is_fitted(self, ['stack_layer_classifier_'])\n",
    "\n",
    "        # Check that the input features match the type and shape of the training features\n",
    "        X = check_array(X)\n",
    "        \n",
    "        X_stack_queries = None\n",
    "        \n",
    "        # Make a prediction with each base classifier\n",
    "        for classifier in self.classifiers_:\n",
    "            \n",
    "            y_pred = classifier.predict_proba(X)\n",
    "                \n",
    "            try:\n",
    "                X_stack_queries = np.c_[X_stack_queries, y_pred]\n",
    "            except ValueError:\n",
    "                X_stack_queries = y_pred\n",
    "\n",
    "        # Return the prediction made by the stack layer classifier        \n",
    "        return self.stack_layer_classifier_.predict_proba(X_stack_queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the StackedEnsembleClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a simple test using the StackedEnsembleClassifier on the Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        50\n",
      "          1       1.00      0.96      0.98        50\n",
      "          2       0.96      1.00      0.98        50\n",
      "\n",
      "avg / total       0.99      0.99      0.99       150\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>50</td>\n",
       "      <td>48</td>\n",
       "      <td>52</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1   2  All\n",
       "True                      \n",
       "0          50   0   0   50\n",
       "1           0  48   2   50\n",
       "2           0   0  50   50\n",
       "All        50  48  52  150"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "clf = StackedEnsembleClassifier()\n",
    "clf.fit(iris.data, iris.target)\n",
    "y_pred = clf.predict(iris.data)\n",
    "print(metrics.classification_report(iris.target, y_pred))\n",
    "print(\"Confusion Matrix\")\n",
    "display(pd.crosstab(np.array(iris.target), y_pred, rownames=['True'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a cross validation experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.93333333 1.         0.93333333 0.93333333 0.93333333\n",
      " 0.93333333 1.         1.         1.        ]\n",
      "0.9666666666666666  +/-  0.033333333333333326\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clf, iris.data, iris.target, cv=10)\n",
    "print(scores)\n",
    "print(np.mean(scores), \" +/- \", np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Design the StackedEnsembleHoldOut Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Design StackedEnsembleHoldOut Class, we have modified the fit method. In this we first split the dataset into training and test dataset. We use <b>training</b> dataset to train all the base models and then use <b>test</b> dataset to generate the training data for the stack layer. Then we train the stack layer model with this newly generated training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackedEnsembleHoldOut(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    \"\"\"An ensemble classifier that uses heterogeneous models at the base layer and a aggregatnio model at the aggregation layer. A k-fold cross validation is used to gnerate training data for the stack layer model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    base_estimators: list \n",
    "        A list of the classifiers in the ase layer of the ensemble. Supported types are\n",
    "        - \"svm\" Support Vector Machine implemented by sklearn.svm.SVC\n",
    "        - \"logreg\" Logistic Regression implemented by sklearn.linear_models.LogisticRegression\n",
    "        - \"knn\" k Nearest Neighbour implemented by sklearn.neighbors.KNeighborsClassifier\n",
    "        - \"tree\" Decision Tree implemented by sklearn.tree.DecisionTreeClassifier\n",
    "        - \"randomforest\" RandomForest implemented by sklearn.tree.RandomForestClassifier    \n",
    "    classifier_duplicates: int, optional (default = 1)\n",
    "        How many instances of each classifier type listed in base_estimators is included in the ensemble\n",
    "    stack_layer_classifier: string, optional (default = \"logreg')\n",
    "        The classifier type used at the stack layer. The same classifier types as are supported at the base layer are supported        \n",
    "    training_folds: int, optional (default = 4)\n",
    "        How many folds will be used to generate the training set for the stacked layer\n",
    "        \n",
    "    Attributes\n",
    "    ----------\n",
    "    classes_ : array of shape = [n_classes] \n",
    "        The classes labels (single output problem).\n",
    "\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The default values for most base learners are used.\n",
    "\n",
    "    See also\n",
    "    --------\n",
    "    \n",
    "    ----------\n",
    "    .. [1]  van der Laan, M., Polley, E. & Hubbard, A. (2007). \n",
    "            Super Learner. Statistical Applications in Genetics \n",
    "            and Molecular Biology, 6(1) \n",
    "            doi:10.2202/1544-6115.1309\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from sklearn.datasets import load_iris\n",
    "    >>> from sklearn.model_selection import cross_val_score\n",
    "    >>> clf = StackedEnsembleClassifier()\n",
    "    >>> iris = load_iris()\n",
    "    >>> cross_val_score(clf, iris.data, iris.target, cv=10)\n",
    "\n",
    "    \"\"\"\n",
    "    # Constructor for the classifier object\n",
    "    def __init__(self, base_estimator_types = [\"svm\", \"logreg\", \"tree\"], base_estimator_duplicates = 8, stack_layer_classifier_type = \"logreg\"):\n",
    "        \"\"\"Setup a SuperLearner classifier .\n",
    "        Parameters\n",
    "        ----------\n",
    "        base_estimator_types: The types of classifiers to include at the base layer\n",
    "        base_estimator_duplicates: The number of duplicates of each type of classiifer to include\n",
    "        stack_layer_classifier_type: The type of classifier to include at the stack layer \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Nothing\n",
    "        \"\"\"     \n",
    "\n",
    "        # Initialise class variabels\n",
    "        self.base_estimator_types = base_estimator_types\n",
    "        self.base_estimator_type_list = list()\n",
    "        self.base_estimator_duplicates = base_estimator_duplicates\n",
    "        self.stack_layer_classifier_type = stack_layer_classifier_type\n",
    "\n",
    "    # The fit function to train a classifier\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Build a SuperLearner classifier from the training set (X, y).\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape = [n_samples, n_features]\n",
    "            The training input samples. \n",
    "        y : array-like, shape = [n_samples] \n",
    "            The target values (class labels) as integers or strings.\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "        \"\"\"    \n",
    "        \n",
    "        # Check that X and y have correct shape\n",
    "        X, y = check_X_y(X, y)\n",
    "        # Store the classes seen during fit\n",
    "        self.classes_ = unique_labels(y)\n",
    "        \n",
    "        ########################\n",
    "        # LEVEL 0\n",
    "        ########################\n",
    "        \n",
    "        # Set up the base classifeirs in the ensemble\n",
    "        self.classifiers_ = list()\n",
    "        \n",
    "        for i in range(0, self.base_estimator_duplicates):\n",
    "            for t in self.base_estimator_types:\n",
    "\n",
    "                self.base_estimator_type_list.append(t)      \n",
    "                c = create_classifier(t, tree_min_samples_split=math.ceil(len(X)*0.05))\n",
    "                self.classifiers_.append(c)\n",
    "        \n",
    "        # Store the number of classifers in the ensemble\n",
    "        self.n_estimators_ = len(self.classifiers_)\n",
    "\n",
    "        #Divide the dataset into training and test set. Training set is used to train the base models and test set \\\n",
    "        #is used to generate the training data for stack layer\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, \\\n",
    "                                           train_size = 0.7)\n",
    "        \n",
    "        \n",
    "        # Set up empty arrays to hold stack layer training data. Since we are using hold out dataset for testing, so \n",
    "        #we will set y_stack_train as y_test. \n",
    "        \n",
    "        self.X_stack_train = None #(dtype = float)\n",
    "        self.y_stack_train = y_test\n",
    "          \n",
    "        # Train each base calssifier and generate the stack layer training dataset\n",
    "        for classifier in self.classifiers_:\n",
    "\n",
    "            # Extract a bootstrap sample\n",
    "            X_train_samp, y_train_samp = resample(X_train, y_train, replace=True)    \n",
    "            \n",
    "            # Train a base classifier\n",
    "            classifier.fit(X_train_samp, y_train_samp)\n",
    "            \n",
    "            # Make predictions for all instances in the test set\n",
    "            y_pred = classifier.predict_proba(X_test)\n",
    "\n",
    "            # Append the predictions at the stack layer training set (a bit of hacking here!)\n",
    "            try:\n",
    "                self.X_stack_train = np.c_[self.X_stack_train, y_pred]                \n",
    "            except ValueError:\n",
    "                self.X_stack_train = y_pred\n",
    "      \n",
    "        ########################\n",
    "        # LEVEL 1\n",
    "        ########################\n",
    "        \n",
    "        # Create the stack layer classifier\n",
    "        self.stack_layer_classifier_ = create_classifier(self.stack_layer_classifier_type, tree_min_samples_split=math.ceil(len(X)*0.05))\n",
    "\n",
    "        # Train the stack layer using the newly created dataset\n",
    "        self.stack_layer_classifier_.fit(self.X_stack_train, self.y_stack_train)\n",
    "            \n",
    "        # Return the classifier\n",
    "        return self\n",
    "\n",
    "    # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels of the input samples X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like matrix of shape = [n_samples, n_features]\n",
    "            The input samples. \n",
    "        Returns\n",
    "        -------\n",
    "        p : array of shape = [n_samples, ].\n",
    "            The predicted class labels of the input samples. \n",
    "        \"\"\"\n",
    "        \n",
    "        # Check is fit had been called by confirming that the teamplates_ dictiponary has been set up\n",
    "        check_is_fitted(self, ['stack_layer_classifier_'])\n",
    "\n",
    "        # Check that the input features match the type and shape of the training features\n",
    "        X = check_array(X)\n",
    "   \n",
    "        X_stack_queries = None\n",
    "              \n",
    "        # Make a prediction with each base classifier and assemble the stack layer query\n",
    "        for classifier in self.classifiers_:\n",
    "            \n",
    "            y_pred = classifier.predict_proba(X)      \n",
    "            try:\n",
    "                X_stack_queries = np.c_[X_stack_queries, y_pred]\n",
    "            except ValueError:\n",
    "                X_stack_queries = y_pred\n",
    "        \n",
    "        # Return the prediction made by the stack layer classifier\n",
    "        return self.stack_layer_classifier_.predict(X_stack_queries)\n",
    "    \n",
    "    # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict class probabilities of the input samples X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like matrix of shape = [n_samples, n_features]\n",
    "            The input samples. \n",
    "        Returns\n",
    "        -------\n",
    "        p : array of shape = [n_samples, n_labels].\n",
    "            The predicted class label probabilities of the input samples. \n",
    "        \"\"\"\n",
    "        # Check is fit had been called by confirming that the teamplates_ dictiponary has been set up\n",
    "        check_is_fitted(self, ['stack_layer_classifier_'])\n",
    "\n",
    "        # Check that the input features match the type and shape of the training features\n",
    "        X = check_array(X)\n",
    "        \n",
    "        X_stack_queries = None\n",
    "        \n",
    "        # Make a prediction with each base classifier\n",
    "        for classifier in self.classifiers_:\n",
    "            \n",
    "            y_pred = classifier.predict_proba(X)\n",
    "                \n",
    "            try:\n",
    "                X_stack_queries = np.c_[X_stack_queries, y_pred]\n",
    "            except ValueError:\n",
    "                X_stack_queries = y_pred\n",
    "\n",
    "        # Return the prediction made by the stack layer classifier        \n",
    "        return self.stack_layer_classifier_.predict_proba(X_stack_queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the StackedEnsembleHoldOutClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a simple test using the StackedEnsembleHoldOutClassifier on the Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        50\n",
      "          1       1.00      0.96      0.98        50\n",
      "          2       0.96      1.00      0.98        50\n",
      "\n",
      "avg / total       0.99      0.99      0.99       150\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>50</td>\n",
       "      <td>48</td>\n",
       "      <td>52</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1   2  All\n",
       "True                      \n",
       "0          50   0   0   50\n",
       "1           0  48   2   50\n",
       "2           0   0  50   50\n",
       "All        50  48  52  150"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "clf = StackedEnsembleHoldOut()\n",
    "clf.fit(iris.data, iris.target)\n",
    "y_pred = clf.predict(iris.data)\n",
    "print(metrics.classification_report(iris.target, y_pred))\n",
    "print(\"Confusion Matrix\")\n",
    "display(pd.crosstab(np.array(iris.target), y_pred, rownames=['True'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Design the StackedEnsembleKFold Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Design StackedEnsembleKFold Class, we have modified the fit method. In this we first split the training data into K-Folds using StratifiedKFold method. All the base models are fitted on the K-1 parts and prediction are made for the Kth part. We repeat this process for each fold of the training data. Predictions which are made on the Kth part are concatenated and given as the training data for the stack layer. At the end we train the base classifiers on the whole dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackedEnsembleKFold(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    \"\"\"An ensemble classifier that uses heterogeneous models at the base layer and a aggregatnio model at the aggregation layer. A k-fold cross validation is used to gnerate training data for the stack layer model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    base_estimators: list \n",
    "        A list of the classifiers in the ase layer of the ensemble. Supported types are\n",
    "        - \"svm\" Support Vector Machine implemented by sklearn.svm.SVC\n",
    "        - \"logreg\" Logistic Regression implemented by sklearn.linear_models.LogisticRegression\n",
    "        - \"knn\" k Nearest Neighbour implemented by sklearn.neighbors.KNeighborsClassifier\n",
    "        - \"tree\" Decision Tree implemented by sklearn.tree.DecisionTreeClassifier\n",
    "        - \"randomforest\" RandomForest implemented by sklearn.tree.RandomForestClassifier    \n",
    "    classifier_duplicates: int, optional (default = 1)\n",
    "        How many instances of each classifier type listed in base_estimators is included in the ensemble\n",
    "    stack_layer_classifier: string, optional (default = \"logreg')\n",
    "        The classifier type used at the stack layer. The same classifier types as are supported at the base layer are supported        \n",
    "    training_folds: int, optional (default = 4)\n",
    "        How many folds will be used to generate the training set for the stacked layer\n",
    "        \n",
    "    Attributes\n",
    "    ----------\n",
    "    classes_ : array of shape = [n_classes] \n",
    "        The classes labels (single output problem).\n",
    "\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The default values for most base learners are used.\n",
    "\n",
    "    See also\n",
    "    --------\n",
    "    \n",
    "    ----------\n",
    "    .. [1]  van der Laan, M., Polley, E. & Hubbard, A. (2007). \n",
    "            Super Learner. Statistical Applications in Genetics \n",
    "            and Molecular Biology, 6(1) \n",
    "            doi:10.2202/1544-6115.1309\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from sklearn.datasets import load_iris\n",
    "    >>> from sklearn.model_selection import cross_val_score\n",
    "    >>> clf = StackedEnsembleClassifier()\n",
    "    >>> iris = load_iris()\n",
    "    >>> cross_val_score(clf, iris.data, iris.target, cv=10)\n",
    "\n",
    "    \"\"\"\n",
    "    # Constructor for the classifier object\n",
    "    def __init__(self, base_estimator_types = [\"svm\", \"logreg\", \"tree\"], base_estimator_duplicates = 1, \\\n",
    "                 stack_layer_classifier_type = \"logreg\", training_folds=4):\n",
    "        \"\"\"Setup a SuperLearner classifier .\n",
    "        Parameters\n",
    "        ----------\n",
    "        base_estimator_types: The types of classifiers to include at the base layer\n",
    "        base_estimator_duplicates: The number of duplicates of each type of classiifer to include\n",
    "        stack_layer_classifier_type: The type of classifier to include at the stack layer \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Nothing\n",
    "        \"\"\"     \n",
    "\n",
    "        # Initialise class variabels\n",
    "        self.base_estimator_types = base_estimator_types\n",
    "        self.base_estimator_type_list = list()\n",
    "        self.base_estimator_duplicates = base_estimator_duplicates\n",
    "        self.stack_layer_classifier_type = stack_layer_classifier_type\n",
    "        self.training_folds = training_folds\n",
    "\n",
    "    # The fit function to train a classifier\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Build a SuperLearner classifier from the training set (X, y).\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape = [n_samples, n_features]\n",
    "            The training input samples. \n",
    "        y : array-like, shape = [n_samples] \n",
    "            The target values (class labels) as integers or strings.\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "        \"\"\"    \n",
    "        \n",
    "        # Check that X and y have correct shape\n",
    "        X, y = check_X_y(X, y)\n",
    "        # Store the classes seen during fit\n",
    "        self.classes_ = unique_labels(y)\n",
    "        \n",
    "        ########################\n",
    "        # LEVEL 0\n",
    "        ########################\n",
    "        \n",
    "        # Set up the base classifeirs in the ensemble\n",
    "        self.classifiers_ = list()\n",
    "        \n",
    "        for i in range(0, self.base_estimator_duplicates):\n",
    "            for t in self.base_estimator_types:\n",
    "\n",
    "                self.base_estimator_type_list.append(t)      \n",
    "                c = create_classifier(t, tree_min_samples_split=math.ceil(len(X)*0.05))\n",
    "                self.classifiers_.append(c)\n",
    "        \n",
    "        # Store the number of classifers in the ensemble\n",
    "        self.n_estimators_ = len(self.classifiers_)\n",
    "\n",
    "        \n",
    "        # we divide the dataset into k-folds using Stratified KFold method\n",
    "        stratified_KFold = StratifiedKFold(n_splits=self.training_folds)\n",
    "        stratified_KFold.get_n_splits(X, y)\n",
    "        \n",
    "        # Set up empty arrays to hold stack layer training data\n",
    "        self.X_stack_train = None #(dtype = float)\n",
    "        #Creating an empty array to store the target value of the instances in the fold which we will use for testing\n",
    "        self.y_stack_train = np.array([]) \n",
    "        \n",
    "        \n",
    "        #We split the training data into K-Folds. Base classifiers are trained on K-1 parts and prediction is \n",
    "        #made on the kth path. We do this process for each part of the training data. This reduces the risk of overfitting\n",
    "        \n",
    "       # Iterate through the K-1 folds to train the model and then we will use the test split (Kth fold)to generate training data for the stack layer\n",
    "        for train_index, test_index in stratified_KFold.split(X, y):\n",
    "            \n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            \n",
    "    \n",
    "            self.y_stack_train = np.r_[self.y_stack_train, y_test]\n",
    "            \n",
    "            X_stack_train_fold = None\n",
    "            \n",
    "            for classifier in self.classifiers_:\n",
    "                # Extract a bootstrap sample\n",
    "                X_train_samp, y_train_samp = resample(X_train, y_train, replace=True) \n",
    "                \n",
    "                # Train a base classifier\n",
    "                classifier.fit(X_train_samp, y_train_samp)\n",
    "                \n",
    "                # Make predictions for all instances in the test set\n",
    "                y_pred = classifier.predict_proba(X_test)\n",
    "                try:\n",
    "                    X_stack_train_fold = np.c_[X_stack_train_fold, y_pred]\n",
    "                except ValueError:\n",
    "                    X_stack_train_fold = y_pred    \n",
    "                \n",
    "            try:\n",
    "                self.X_stack_train = np.r_[self.X_stack_train, X_stack_train_fold]\n",
    "            except ValueError:\n",
    "                self.X_stack_train = X_stack_train_fold    \n",
    "            \n",
    "        ########################\n",
    "        # LEVEL 1\n",
    "        ########################\n",
    "        \n",
    "        # Create the stack layer classifier\n",
    "        self.stack_layer_classifier_ = create_classifier(self.stack_layer_classifier_type, tree_min_samples_split=math.ceil(len(X)*0.05))\n",
    "\n",
    "        # Train the stack layer using the newly created dataset\n",
    "        self.stack_layer_classifier_.fit(self.X_stack_train, self.y_stack_train)\n",
    "        \n",
    "        \n",
    "        # Re-train the base classifiers in the ensemble using the full dataset            \n",
    "        \n",
    "        self.classifiers_ = list()\n",
    "        \n",
    "        for i in range(0, self.base_estimator_duplicates):\n",
    "            for t in self.base_estimator_types:      \n",
    "                c = create_classifier(t, tree_min_samples_split=math.ceil(len(X)*0.05))\n",
    "                \n",
    "                # Extract a bootstrap sample\n",
    "                X_train_samp, y_train_samp = resample(X, y, replace=True)\n",
    "                # Train a base classifier\n",
    "                c.fit(X_train_samp, y_train_samp)\n",
    "                self.classifiers_.append(c)\n",
    "        \n",
    "        # Return the classifier\n",
    "        return self\n",
    "\n",
    "    # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels of the input samples X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like matrix of shape = [n_samples, n_features]\n",
    "            The input samples. \n",
    "        Returns\n",
    "        -------\n",
    "        p : array of shape = [n_samples, ].\n",
    "            The predicted class labels of the input samples. \n",
    "        \"\"\"\n",
    "        \n",
    "        # Check is fit had been called by confirming that the teamplates_ dictiponary has been set up\n",
    "        check_is_fitted(self, ['stack_layer_classifier_'])\n",
    "\n",
    "        # Check that the input features match the type and shape of the training features\n",
    "        X = check_array(X)\n",
    "   \n",
    "        X_stack_queries = None\n",
    "              \n",
    "        # Make a prediction with each base classifier and assemble the stack layer query\n",
    "        for classifier in self.classifiers_:\n",
    "            \n",
    "            y_pred = classifier.predict_proba(X)\n",
    "            \n",
    "            try:\n",
    "                X_stack_queries = np.c_[X_stack_queries, y_pred]\n",
    "            except ValueError:\n",
    "                X_stack_queries = y_pred\n",
    "        \n",
    "        # Return the prediction made by the stack layer classifier\n",
    "        return self.stack_layer_classifier_.predict(X_stack_queries)\n",
    "    \n",
    "    # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict class probabilities of the input samples X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like matrix of shape = [n_samples, n_features]\n",
    "            The input samples. \n",
    "        Returns\n",
    "        -------\n",
    "        p : array of shape = [n_samples, n_labels].\n",
    "            The predicted class label probabilities of the input samples. \n",
    "        \"\"\"\n",
    "        # Check is fit had been called by confirming that the teamplates_ dictiponary has been set up\n",
    "        check_is_fitted(self, ['stack_layer_classifier_'])\n",
    "\n",
    "        # Check that the input features match the type and shape of the training features\n",
    "        X = check_array(X)\n",
    "        \n",
    "        X_stack_queries = None\n",
    "        \n",
    "        # Make a prediction with each base classifier\n",
    "        for classifier in self.classifiers_:\n",
    "            \n",
    "            y_pred = classifier.predict_proba(X)\n",
    "                \n",
    "            try:\n",
    "                X_stack_queries = np.c_[X_stack_queries, y_pred]\n",
    "            except ValueError:\n",
    "                X_stack_queries = y_pred\n",
    "\n",
    "        # Return the prediction made by the stack layer classifier        \n",
    "        return self.stack_layer_classifier_.predict_proba(X_stack_queries)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the StackedEnsembleKFoldClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a simple test using the StackedEnsembleKFoldClassifier on the Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        50\n",
      "          1       1.00      0.96      0.98        50\n",
      "          2       0.96      1.00      0.98        50\n",
      "\n",
      "avg / total       0.99      0.99      0.99       150\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>50</td>\n",
       "      <td>48</td>\n",
       "      <td>52</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  0.0  1.0  2.0  All\n",
       "True                         \n",
       "0           50    0    0   50\n",
       "1            0   48    2   50\n",
       "2            0    0   50   50\n",
       "All         50   48   52  150"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "clf = StackedEnsembleKFold()\n",
    "clf.fit(iris.data, iris.target)\n",
    "y_pred = clf.predict(iris.data)\n",
    "print(metrics.classification_report(iris.target, y_pred))\n",
    "print(\"Confusion Matrix\")\n",
    "display(pd.crosstab(np.array(iris.target), y_pred, rownames=['True'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a cross validation experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.93333333 1.         1.         0.93333333 1.\n",
      " 0.93333333 1.         1.         1.        ]\n",
      "0.9800000000000001  +/-  0.030550504633038926\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clf, iris.data, iris.target, cv=10)\n",
    "print(scores)\n",
    "print(np.mean(scores), \" +/- \", np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Compare the Performance of Different Stack Layer Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Compare the performance of different stack layer approaches, we have taken 24 base classifiers using a mixture of decision trees, support vector machines and logistic regression models. For this I have set the <b>base_estimator_types = [\"svm\", \"logreg\", \"tree\"]</b> and <b>base_estimator_duplicates = 8 </b>. At stack layer, in one scenario we are using <b>logistic regression model</b> and in another we are using <b>decision trees</b>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup- Take only a sample of the dataset for fast testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sampling_rate = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the number of folds for all grid searches (should be 5 - 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_folds = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up a dictionary to store simple model perofrmance comparions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test_accuracy_comparisons = dict()\n",
    "model_valid_accuracy_comparisons = dict()\n",
    "model_test_f1_comparisons = dict()\n",
    "model_valid_f1_comparisons = dict()\n",
    "model_tuned_params_list = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load & Partition Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53566</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19965</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>173</td>\n",
       "      <td>184</td>\n",
       "      <td>...</td>\n",
       "      <td>158</td>\n",
       "      <td>143</td>\n",
       "      <td>121</td>\n",
       "      <td>107</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51904</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>133</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12743</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>184</td>\n",
       "      <td>116</td>\n",
       "      <td>84</td>\n",
       "      <td>89</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59505</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "53566      5       0       0       0       0       0       0       0       0   \n",
       "19965      2       0       0       0       0       0       0      60     173   \n",
       "51904      0       0       0       0       0       0       0       0       0   \n",
       "12743      2       0       0       2       0       1       0       0       0   \n",
       "59505      5       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "53566       0  ...         0         0         0         0         0   \n",
       "19965     184  ...       158       143       121       107        38   \n",
       "51904       0  ...       133        89         0         0         0   \n",
       "12743       0  ...       184       116        84        89        29   \n",
       "59505       0  ...         0         0         0         0         0   \n",
       "\n",
       "       pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "53566         0         0         0         0         0  \n",
       "19965         0         0         0         0         0  \n",
       "51904         0         0         0         0         0  \n",
       "12743         0         0         0         0         0  \n",
       "59505         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = pd.read_csv('fashion-mnist_train.csv')\n",
    "dataset = dataset.sample(frac=data_sampling_rate) #take a sample from the dataset so everyhting runs smoothly\n",
    "num_classes = 10\n",
    "classes = {0: \"T-shirt/top\", 1:\"Trouser\", 2: \"Pullover\", 3:\"Dress\", 4:\"Coat\", 5:\"Sandal\", 6:\"Shirt\", 7:\"Sneaker\", 8:\"Bag\", 9:\"Ankle boot\"}\n",
    "display(dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partitioning and Pre-processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[dataset.columns[1:]]\n",
    "Y = np.array(dataset[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividing the dataset into train, test and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train_plus_valid, X_test, y_train_plus_valid, y_test \\\n",
    "    = train_test_split(X, Y, random_state=0, \\\n",
    "                                    train_size = 0.7)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid \\\n",
    "    = train_test_split(X_train_plus_valid, \\\n",
    "                                        y_train_plus_valid, \\\n",
    "                                        random_state=0, \\\n",
    "                                        train_size = 0.5/0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StackedEnsembleClassifier with Logistic regression model at Stack Layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Stacked Ensemble Classifier model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackedEnsembleClassifier(base_estimator_duplicates=8,\n",
       "             base_estimator_types=['svm', 'logreg', 'tree'],\n",
       "             stack_layer_classifier_type='logreg')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stackedEnsembleModel = StackedEnsembleClassifier(base_estimator_types = [\"svm\", \"logreg\", \"tree\"],\\\n",
    "                                                 base_estimator_duplicates = 8, stack_layer_classifier_type = \"logreg\")\n",
    "stackedEnsembleModel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the performance of the ensemble tree on the <b>training set</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9873333333333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.98      0.98       121\n",
      "          1       1.00      1.00      1.00       142\n",
      "          2       0.98      0.96      0.97       169\n",
      "          3       0.99      1.00      1.00       147\n",
      "          4       0.96      0.98      0.97       147\n",
      "          5       1.00      1.00      1.00       142\n",
      "          6       0.98      0.96      0.97       167\n",
      "          7       0.99      1.00      1.00       149\n",
      "          8       1.00      1.00      1.00       158\n",
      "          9       1.00      0.99      1.00       158\n",
      "\n",
      "avg / total       0.99      0.99      0.99      1500\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>149</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>121</td>\n",
       "      <td>142</td>\n",
       "      <td>167</td>\n",
       "      <td>148</td>\n",
       "      <td>150</td>\n",
       "      <td>142</td>\n",
       "      <td>165</td>\n",
       "      <td>150</td>\n",
       "      <td>158</td>\n",
       "      <td>157</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0          118    0    1    1    0    0    1    0    0    0   121\n",
       "1            0  142    0    0    0    0    0    0    0    0   142\n",
       "2            1    0  163    0    4    0    1    0    0    0   169\n",
       "3            0    0    0  147    0    0    0    0    0    0   147\n",
       "4            0    0    1    0  144    0    2    0    0    0   147\n",
       "5            0    0    0    0    0  142    0    0    0    0   142\n",
       "6            2    0    2    0    2    0  161    0    0    0   167\n",
       "7            0    0    0    0    0    0    0  149    0    0   149\n",
       "8            0    0    0    0    0    0    0    0  158    0   158\n",
       "9            0    0    0    0    0    0    0    1    0  157   158\n",
       "All        121  142  167  148  150  142  165  150  158  157  1500"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = stackedEnsembleModel.predict(X_train)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_train, y_pred) # , normalize=True, sample_weight=None\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_train, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "display(pd.crosstab(np.array(y_train), y_pred, rownames=['True'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the performance of the ensemble on the <b>validation dataset</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.81\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.87      0.85        52\n",
      "          1       0.97      0.97      0.97        58\n",
      "          2       0.73      0.71      0.72        69\n",
      "          3       0.79      0.90      0.84        63\n",
      "          4       0.72      0.62      0.67        63\n",
      "          5       0.85      0.87      0.86        54\n",
      "          6       0.54      0.54      0.54        56\n",
      "          7       0.84      0.85      0.84        60\n",
      "          8       0.93      0.92      0.92        73\n",
      "          9       0.88      0.87      0.87        52\n",
      "\n",
      "avg / total       0.81      0.81      0.81       600\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>54</td>\n",
       "      <td>58</td>\n",
       "      <td>67</td>\n",
       "      <td>72</td>\n",
       "      <td>54</td>\n",
       "      <td>55</td>\n",
       "      <td>56</td>\n",
       "      <td>61</td>\n",
       "      <td>72</td>\n",
       "      <td>51</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1   2   3   4   5   6   7   8   9  All\n",
       "True                                                  \n",
       "0          45   0   1   2   0   0   4   0   0   0   52\n",
       "1           0  56   1   0   0   0   0   0   1   0   58\n",
       "2           0   0  49   1  12   0   7   0   0   0   69\n",
       "3           1   2   1  57   2   0   0   0   0   0   63\n",
       "4           0   0   9   3  39   0  12   0   0   0   63\n",
       "5           0   0   0   0   0  47   0   4   1   2   54\n",
       "6           8   0   6   8   1   0  30   0   3   0   56\n",
       "7           0   0   0   0   0   5   0  51   0   4   60\n",
       "8           0   0   0   1   0   1   3   1  67   0   73\n",
       "9           0   0   0   0   0   2   0   5   0  45   52\n",
       "All        54  58  67  72  54  55  56  61  72  51  600"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = stackedEnsembleModel.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "model_valid_accuracy_comparisons[\"StackedEnsembleClassifier LogisticRegression\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "report = metrics.classification_report(y_valid, y_pred)\n",
    "model_valid_f1_comparisons[\"StackedEnsembleClassifier LogisticRegression\"] = report.split('\\n')[-2].split('      ')[3]\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the performance of the tree on the <b>test dataset</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8044444444444444\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.72      0.73        90\n",
      "          1       0.98      0.95      0.97       102\n",
      "          2       0.68      0.72      0.70        87\n",
      "          3       0.75      0.89      0.81        76\n",
      "          4       0.70      0.64      0.67        81\n",
      "          5       0.93      0.88      0.90        86\n",
      "          6       0.54      0.48      0.51       104\n",
      "          7       0.90      0.88      0.89        98\n",
      "          8       0.92      0.95      0.93        92\n",
      "          9       0.87      0.95      0.91        84\n",
      "\n",
      "avg / total       0.80      0.80      0.80       900\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>87</td>\n",
       "      <td>99</td>\n",
       "      <td>92</td>\n",
       "      <td>91</td>\n",
       "      <td>74</td>\n",
       "      <td>82</td>\n",
       "      <td>92</td>\n",
       "      <td>96</td>\n",
       "      <td>95</td>\n",
       "      <td>92</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1   2   3   4   5   6   7   8   9  All\n",
       "True                                                  \n",
       "0          65   0   3   9   1   1  10   0   1   0   90\n",
       "1           0  97   1   2   0   0   2   0   0   0  102\n",
       "2           2   0  63   0   7   0  14   0   1   0   87\n",
       "3           1   2   2  68   2   0   1   0   0   0   76\n",
       "4           1   0   7   7  52   0  14   0   0   0   81\n",
       "5           0   0   0   0   0  76   0   6   0   4   86\n",
       "6          17   0  15   4  12   0  50   0   6   0  104\n",
       "7           0   0   0   0   0   4   0  86   0   8   98\n",
       "8           1   0   1   1   0   0   1   1  87   0   92\n",
       "9           0   0   0   0   0   1   0   3   0  80   84\n",
       "All        87  99  92  91  74  82  92  96  95  92  900"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = stackedEnsembleModel.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"StackedEnsembleClassifier LogisticRegression\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "report = metrics.classification_report(y_test, y_pred)\n",
    "model_test_f1_comparisons[\"StackedEnsembleClassifier LogisticRegression\"] = report.split('\\n')[-2].split('      ')[3]\n",
    "# Print confusion matrix\n",
    "#print(metrics.confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Print nicer confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfrom a cross validation experiment to evaluate the performance of the StackedEnsembleClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 2.1min\n",
      "[CV] ................................................. , total= 2.1min\n",
      "[CV] ................................................. , total= 2.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  2.1min remaining:  1.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total= 2.1min\n",
      "[CV] ................................................. , total= 2.1min\n",
      "[0.81560284 0.78622328 0.80047506 0.80143541 0.8057554 ]\n",
      "0.8018983953107224  +/-  0.00949355275689598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  2.1min finished\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(stackedEnsembleModel,X_train_plus_valid, y_train_plus_valid, cv=cv_folds, \\\n",
    "                         n_jobs=-1, verbose = 2)\n",
    "print(scores)\n",
    "print(np.mean(scores), \" +/- \", np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StackedEnsembleClassifierHoldOut with Logistic regression model at Stack Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackedEnsembleHoldOut(base_estimator_duplicates=8,\n",
       "            base_estimator_types=['svm', 'logreg', 'tree'],\n",
       "            stack_layer_classifier_type='logreg')"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stackedEnsembleHoldOutModel = StackedEnsembleHoldOut(base_estimator_types = [\"svm\", \"logreg\", \"tree\"], \\\n",
    "                                                     base_estimator_duplicates = 8,\\\n",
    "                                                     stack_layer_classifier_type = \"logreg\")\n",
    "stackedEnsembleHoldOutModel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the performance of the ensemble tree on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9053333333333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.75      0.82       121\n",
      "          1       0.99      0.97      0.98       142\n",
      "          2       0.88      0.84      0.86       169\n",
      "          3       0.84      0.95      0.89       147\n",
      "          4       0.84      0.85      0.85       147\n",
      "          5       0.95      0.97      0.96       142\n",
      "          6       0.77      0.81      0.79       167\n",
      "          7       0.96      0.95      0.96       149\n",
      "          8       0.98      0.99      0.98       158\n",
      "          9       0.96      0.96      0.96       158\n",
      "\n",
      "avg / total       0.91      0.91      0.91      1500\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>139</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>100</td>\n",
       "      <td>140</td>\n",
       "      <td>161</td>\n",
       "      <td>165</td>\n",
       "      <td>148</td>\n",
       "      <td>145</td>\n",
       "      <td>177</td>\n",
       "      <td>148</td>\n",
       "      <td>159</td>\n",
       "      <td>157</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0           91    0    3   11    0    0   16    0    0    0   121\n",
       "1            0  138    0    4    0    0    0    0    0    0   142\n",
       "2            2    0  142    3   11    0   11    0    0    0   169\n",
       "3            1    2    2  139    1    0    2    0    0    0   147\n",
       "4            0    0    5    4  125    0   12    0    1    0   147\n",
       "5            0    0    0    0    0  138    0    2    0    2   142\n",
       "6            6    0    9    3   11    0  136    0    2    0   167\n",
       "7            0    0    0    0    0    3    0  142    0    4   149\n",
       "8            0    0    0    1    0    0    0    1  156    0   158\n",
       "9            0    0    0    0    0    4    0    3    0  151   158\n",
       "All        100  140  161  165  148  145  177  148  159  157  1500"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = stackedEnsembleHoldOutModel.predict(X_train)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_train, y_pred) # , normalize=True, sample_weight=None\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_train, y_pred))\n",
    "\n",
    "# Print nicer homemade confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "display(pd.crosstab(np.array(y_train), y_pred, rownames=['True'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the performance of the ensemble on the <b>validation dataset</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.73      0.77        52\n",
      "          1       1.00      0.97      0.98        58\n",
      "          2       0.81      0.68      0.74        69\n",
      "          3       0.74      0.90      0.81        63\n",
      "          4       0.72      0.65      0.68        63\n",
      "          5       0.84      0.85      0.84        54\n",
      "          6       0.49      0.59      0.54        56\n",
      "          7       0.82      0.92      0.87        60\n",
      "          8       0.93      0.89      0.91        73\n",
      "          9       0.91      0.81      0.86        52\n",
      "\n",
      "avg / total       0.81      0.80      0.80       600\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>47</td>\n",
       "      <td>56</td>\n",
       "      <td>58</td>\n",
       "      <td>77</td>\n",
       "      <td>57</td>\n",
       "      <td>55</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>70</td>\n",
       "      <td>46</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1   2   3   4   5   6   7   8   9  All\n",
       "True                                                  \n",
       "0          38   0   2   7   0   0   5   0   0   0   52\n",
       "1           0  56   0   0   0   0   1   0   1   0   58\n",
       "2           0   0  47   0  11   0  11   0   0   0   69\n",
       "3           2   0   1  57   2   0   1   0   0   0   63\n",
       "4           0   0   3   6  41   0  13   0   0   0   63\n",
       "5           0   0   0   0   0  46   0   5   1   2   54\n",
       "6           7   0   5   6   2   0  33   0   3   0   56\n",
       "7           0   0   0   0   0   3   0  55   0   2   60\n",
       "8           0   0   0   1   1   1   3   2  65   0   73\n",
       "9           0   0   0   0   0   5   0   5   0  42   52\n",
       "All        47  56  58  77  57  55  67  67  70  46  600"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = stackedEnsembleHoldOutModel.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "model_valid_accuracy_comparisons[\"StackedEnsembleHoldOutClassifier LogisticRegression\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "report = metrics.classification_report(y_valid, y_pred)\n",
    "model_valid_f1_comparisons[\"StackedEnsembleHoldOutClassifier LogisticRegression\"] = report.split('\\n')[-2].split('      ')[3]\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the performance of the tree on the <b>test dataset</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8033333333333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.67      0.73        90\n",
      "          1       0.99      0.96      0.98       102\n",
      "          2       0.71      0.69      0.70        87\n",
      "          3       0.72      0.91      0.80        76\n",
      "          4       0.69      0.72      0.70        81\n",
      "          5       0.89      0.92      0.90        86\n",
      "          6       0.52      0.47      0.49       104\n",
      "          7       0.91      0.88      0.90        98\n",
      "          8       0.92      0.98      0.95        92\n",
      "          9       0.86      0.88      0.87        84\n",
      "\n",
      "avg / total       0.80      0.80      0.80       900\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>74</td>\n",
       "      <td>99</td>\n",
       "      <td>85</td>\n",
       "      <td>96</td>\n",
       "      <td>84</td>\n",
       "      <td>89</td>\n",
       "      <td>95</td>\n",
       "      <td>94</td>\n",
       "      <td>98</td>\n",
       "      <td>86</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1   2   3   4   5   6   7   8   9  All\n",
       "True                                                  \n",
       "0          60   0   1  12   0   1  15   0   1   0   90\n",
       "1           0  98   1   2   0   0   1   0   0   0  102\n",
       "2           0   0  60   0  12   0  14   0   1   0   87\n",
       "3           2   1   2  69   0   0   2   0   0   0   76\n",
       "4           0   0   3   6  58   0  13   0   1   0   81\n",
       "5           0   0   0   0   0  79   0   4   0   3   86\n",
       "6          12   0  18   6  14   0  49   0   5   0  104\n",
       "7           0   0   0   0   0   3   0  86   0   9   98\n",
       "8           0   0   0   1   0   0   1   0  90   0   92\n",
       "9           0   0   0   0   0   6   0   4   0  74   84\n",
       "All        74  99  85  96  84  89  95  94  98  86  900"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = stackedEnsembleHoldOutModel.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"StackedEnsembleHoldOutClassifier LogisticRegression\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "report = metrics.classification_report(y_test, y_pred)\n",
    "model_test_f1_comparisons[\"StackedEnsembleHoldOutClassifier LogisticRegression\"] = report.split('\\n')[-2].split('      ')[3]\n",
    "\n",
    "# Print confusion matrix\n",
    "#print(metrics.confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Print nicer confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfrom a cross validation experiment to evaluate the performance of the StackedEnsembleHoldOutClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total= 1.0min\n",
      "[CV] ................................................. , total= 1.0min\n",
      "[CV] ................................................. , total= 1.1min\n",
      "[CV] ................................................. , total= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  1.1min remaining:   42.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total= 1.1min\n",
      "[0.79669031 0.79572447 0.78384798 0.80382775 0.79376499]\n",
      "0.7947710986180379  +/-  0.006433381437846476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.1min finished\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(stackedEnsembleHoldOutModel,X_train_plus_valid, y_train_plus_valid, cv=cv_folds, \\\n",
    "                         n_jobs=-1, verbose = 2)\n",
    "print(scores)\n",
    "print(np.mean(scores), \" +/- \", np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StackedEnsembleClassifierkFold  with Logistic regression model at Stack Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackedEnsembleKFold(base_estimator_duplicates=8,\n",
       "           base_estimator_types=['svm', 'logreg', 'tree'],\n",
       "           stack_layer_classifier_type='logreg', training_folds=4)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stackedEnsembleKFoldModel = StackedEnsembleKFold(base_estimator_types = [\"svm\", \"logreg\", \"tree\"], \\\n",
    "                                                 base_estimator_duplicates = 8, \\\n",
    "                                                 stack_layer_classifier_type = \"logreg\")\n",
    "stackedEnsembleKFoldModel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the performance of the ensemble tree on the <b>training set</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9166666666666666\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.86      0.84       121\n",
      "          1       0.99      0.97      0.98       142\n",
      "          2       0.89      0.92      0.90       169\n",
      "          3       0.86      0.93      0.89       147\n",
      "          4       0.88      0.84      0.86       147\n",
      "          5       0.97      0.99      0.98       142\n",
      "          6       0.83      0.75      0.79       167\n",
      "          7       0.98      0.95      0.97       149\n",
      "          8       0.97      0.98      0.98       158\n",
      "          9       0.96      0.97      0.97       158\n",
      "\n",
      "avg / total       0.92      0.92      0.92      1500\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>6.0</th>\n",
       "      <th>7.0</th>\n",
       "      <th>8.0</th>\n",
       "      <th>9.0</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>137</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>127</td>\n",
       "      <td>139</td>\n",
       "      <td>176</td>\n",
       "      <td>160</td>\n",
       "      <td>139</td>\n",
       "      <td>145</td>\n",
       "      <td>150</td>\n",
       "      <td>145</td>\n",
       "      <td>159</td>\n",
       "      <td>160</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  0.0  1.0  2.0  3.0  4.0  5.0  6.0  7.0  8.0  9.0   All\n",
       "True                                                             \n",
       "0          104    0    1    8    1    0    7    0    0    0   121\n",
       "1            0  138    0    4    0    0    0    0    0    0   142\n",
       "2            3    0  156    1    4    0    5    0    0    0   169\n",
       "3            3    1    1  137    4    0    1    0    0    0   147\n",
       "4            0    0    7    5  123    0   11    0    1    0   147\n",
       "5            0    0    0    0    0  141    0    0    0    1   142\n",
       "6           17    0   11    4    7    0  125    0    3    0   167\n",
       "7            0    0    0    0    0    2    0  142    0    5   149\n",
       "8            0    0    0    1    0    0    1    1  155    0   158\n",
       "9            0    0    0    0    0    2    0    2    0  154   158\n",
       "All        127  139  176  160  139  145  150  145  159  160  1500"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = stackedEnsembleKFoldModel.predict(X_train)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_train, y_pred) # , normalize=True, sample_weight=None\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_train, y_pred))\n",
    "\n",
    "# Print nicer homemade confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "display(pd.crosstab(np.array(y_train), y_pred, rownames=['True'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the performance of the ensemble on the <b>validation dataset</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8116666666666666\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.81      0.82        52\n",
      "          1       1.00      0.97      0.98        58\n",
      "          2       0.77      0.80      0.79        69\n",
      "          3       0.72      0.89      0.79        63\n",
      "          4       0.73      0.59      0.65        63\n",
      "          5       0.85      0.87      0.86        54\n",
      "          6       0.57      0.55      0.56        56\n",
      "          7       0.84      0.85      0.84        60\n",
      "          8       0.93      0.92      0.92        73\n",
      "          9       0.88      0.87      0.87        52\n",
      "\n",
      "avg / total       0.81      0.81      0.81       600\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>6.0</th>\n",
       "      <th>7.0</th>\n",
       "      <th>8.0</th>\n",
       "      <th>9.0</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>51</td>\n",
       "      <td>56</td>\n",
       "      <td>71</td>\n",
       "      <td>78</td>\n",
       "      <td>51</td>\n",
       "      <td>55</td>\n",
       "      <td>54</td>\n",
       "      <td>61</td>\n",
       "      <td>72</td>\n",
       "      <td>51</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  0.0  1.0  2.0  3.0  4.0  5.0  6.0  7.0  8.0  9.0  All\n",
       "True                                                            \n",
       "0           42    0    0    6    0    0    4    0    0    0   52\n",
       "1            0   56    1    0    0    0    0    0    1    0   58\n",
       "2            1    0   55    2    8    0    3    0    0    0   69\n",
       "3            1    0    1   56    4    0    1    0    0    0   63\n",
       "4            0    0    8    5   37    0   13    0    0    0   63\n",
       "5            0    0    0    0    0   47    0    4    1    2   54\n",
       "6            7    0    6    8    1    0   31    0    3    0   56\n",
       "7            0    0    0    0    0    5    0   51    0    4   60\n",
       "8            0    0    0    1    1    1    2    1   67    0   73\n",
       "9            0    0    0    0    0    2    0    5    0   45   52\n",
       "All         51   56   71   78   51   55   54   61   72   51  600"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = stackedEnsembleKFoldModel.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "model_valid_accuracy_comparisons[\"StackedEnsembleKFoldClassifier LogisticRegression\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "report = metrics.classification_report(y_valid, y_pred)\n",
    "model_valid_f1_comparisons[\"StackedEnsembleKFoldClassifier LogisticRegression\"] = report.split('\\n')[-2].split('      ')[3]\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the performance of the tree on the <b>test dataset</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7977777777777778\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.73      0.73        90\n",
      "          1       0.98      0.95      0.97       102\n",
      "          2       0.66      0.72      0.69        87\n",
      "          3       0.72      0.89      0.80        76\n",
      "          4       0.71      0.63      0.67        81\n",
      "          5       0.91      0.92      0.91        86\n",
      "          6       0.55      0.43      0.48       104\n",
      "          7       0.91      0.85      0.88        98\n",
      "          8       0.92      0.96      0.94        92\n",
      "          9       0.86      0.93      0.89        84\n",
      "\n",
      "avg / total       0.79      0.80      0.79       900\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>6.0</th>\n",
       "      <th>7.0</th>\n",
       "      <th>8.0</th>\n",
       "      <th>9.0</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>91</td>\n",
       "      <td>99</td>\n",
       "      <td>96</td>\n",
       "      <td>95</td>\n",
       "      <td>72</td>\n",
       "      <td>87</td>\n",
       "      <td>82</td>\n",
       "      <td>91</td>\n",
       "      <td>96</td>\n",
       "      <td>91</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  0.0  1.0  2.0  3.0  4.0  5.0  6.0  7.0  8.0  9.0  All\n",
       "True                                                            \n",
       "0           66    0    2   14    0    1    6    0    1    0   90\n",
       "1            0   97    2    2    0    0    1    0    0    0  102\n",
       "2            1    0   63    0   10    0   12    0    1    0   87\n",
       "3            5    0    1   68    0    0    2    0    0    0   76\n",
       "4            0    2    7    7   51    0   14    0    0    0   81\n",
       "5            0    0    0    0    0   79    0    4    0    3   86\n",
       "6           19    0   20    3   11    0   45    0    6    0  104\n",
       "7            0    0    0    0    0    5    0   83    0   10   98\n",
       "8            0    0    1    1    0    0    2    0   88    0   92\n",
       "9            0    0    0    0    0    2    0    4    0   78   84\n",
       "All         91   99   96   95   72   87   82   91   96   91  900"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = stackedEnsembleKFoldModel.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"StackedEnsembleKFoldClassifier LogisticRegression\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "report = metrics.classification_report(y_test, y_pred)\n",
    "model_test_f1_comparisons[\"StackedEnsembleKFoldClassifier LogisticRegression\"] = report.split('\\n')[-2].split('      ')[3]\n",
    "\n",
    "# Print nicer confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfrom a cross validation experiment to evaluate the performance of the StackedEnsembleKFoldClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 6.2min\n",
      "[CV] ................................................. , total= 6.4min\n",
      "[CV] ................................................. , total= 6.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  6.4min remaining:  4.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total= 6.4min\n",
      "[CV] ................................................. , total= 6.5min\n",
      "[0.8179669  0.78384798 0.7719715  0.78229665 0.79376499]\n",
      "0.7899696038470523  +/-  0.015611111755939475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  6.5min finished\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(stackedEnsembleKFoldModel,X_train_plus_valid, y_train_plus_valid, cv=cv_folds, \\\n",
    "                         n_jobs=-1, verbose = 2)\n",
    "print(scores)\n",
    "print(np.mean(scores), \" +/- \", np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StackedEnsembleClassifier with Decision Tree model at Stack Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackedEnsembleClassifier(base_estimator_duplicates=8,\n",
       "             base_estimator_types=['svm', 'logreg', 'tree'],\n",
       "             stack_layer_classifier_type='tree')"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StackedEnsembleClassifierTree = StackedEnsembleClassifier(base_estimator_types = [\"svm\", \"logreg\", \"tree\"], \\\n",
    "                                                          base_estimator_duplicates = 8,\\\n",
    "                                                          stack_layer_classifier_type = \"tree\")\n",
    "StackedEnsembleClassifierTree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the performance of the ensemble tree on the <b>training set</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9486666666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.94      0.95       121\n",
      "          1       1.00      1.00      1.00       142\n",
      "          2       0.73      0.98      0.84       169\n",
      "          3       1.00      0.89      0.94       147\n",
      "          4       0.94      0.91      0.93       147\n",
      "          5       1.00      0.99      1.00       142\n",
      "          6       0.99      0.81      0.89       167\n",
      "          7       0.99      0.99      0.99       149\n",
      "          8       1.00      0.97      0.99       158\n",
      "          9       1.00      0.99      1.00       158\n",
      "\n",
      "avg / total       0.96      0.95      0.95      1500\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>131</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>119</td>\n",
       "      <td>142</td>\n",
       "      <td>227</td>\n",
       "      <td>131</td>\n",
       "      <td>142</td>\n",
       "      <td>141</td>\n",
       "      <td>138</td>\n",
       "      <td>149</td>\n",
       "      <td>154</td>\n",
       "      <td>157</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0          114    0    4    0    1    0    2    0    0    0   121\n",
       "1            0  142    0    0    0    0    0    0    0    0   142\n",
       "2            1    0  166    0    2    0    0    0    0    0   169\n",
       "3            2    0   13  131    1    0    0    0    0    0   147\n",
       "4            0    0   13    0  134    0    0    0    0    0   147\n",
       "5            0    0    0    0    0  141    0    1    0    0   142\n",
       "6            2    0   25    0    4    0  136    0    0    0   167\n",
       "7            0    0    1    0    0    0    0  148    0    0   149\n",
       "8            0    0    4    0    0    0    0    0  154    0   158\n",
       "9            0    0    1    0    0    0    0    0    0  157   158\n",
       "All        119  142  227  131  142  141  138  149  154  157  1500"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = StackedEnsembleClassifierTree.predict(X_train)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_train, y_pred) # , normalize=True, sample_weight=None\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_train, y_pred))\n",
    "\n",
    "# Print nicer homemade confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "display(pd.crosstab(np.array(y_train), y_pred, rownames=['True'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the performance of the ensemble tree on the <b>Validation set</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7766666666666666\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.79      0.80        52\n",
      "          1       1.00      0.95      0.97        58\n",
      "          2       0.51      0.68      0.58        69\n",
      "          3       0.85      0.81      0.83        63\n",
      "          4       0.67      0.63      0.65        63\n",
      "          5       0.85      0.87      0.86        54\n",
      "          6       0.53      0.45      0.49        56\n",
      "          7       0.82      0.88      0.85        60\n",
      "          8       0.92      0.84      0.88        73\n",
      "          9       0.94      0.88      0.91        52\n",
      "\n",
      "avg / total       0.79      0.78      0.78       600\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>51</td>\n",
       "      <td>55</td>\n",
       "      <td>92</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>55</td>\n",
       "      <td>47</td>\n",
       "      <td>65</td>\n",
       "      <td>66</td>\n",
       "      <td>49</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1   2   3   4   5   6   7   8   9  All\n",
       "True                                                  \n",
       "0          41   0   4   0   1   0   6   0   0   0   52\n",
       "1           0  55   2   0   0   0   0   0   1   0   58\n",
       "2           0   0  47   1  12   1   8   0   0   0   69\n",
       "3           3   0   5  51   3   0   1   0   0   0   63\n",
       "4           0   0  13   4  40   0   6   0   0   0   63\n",
       "5           0   0   0   0   0  47   0   5   1   1   54\n",
       "6           7   0  16   3   2   0  25   0   3   0   56\n",
       "7           0   0   1   0   0   4   0  53   0   2   60\n",
       "8           0   0   4   1   2   2   1   2  61   0   73\n",
       "9           0   0   0   0   0   1   0   5   0  46   52\n",
       "All        51  55  92  60  60  55  47  65  66  49  600"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = StackedEnsembleClassifierTree.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "model_valid_accuracy_comparisons[\"StackedEnsembleClassifier DecisionTree\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "report = metrics.classification_report(y_valid, y_pred)\n",
    "model_valid_f1_comparisons[\"StackedEnsembleClassifier DecisionTree\"] = report.split('\\n')[-2].split('      ')[3]\n",
    "\n",
    "\n",
    "# Print nicer homemade confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "display(pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the performance of the ensemble tree on the <b>Test set</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7755555555555556\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.68      0.71        90\n",
      "          1       1.00      0.94      0.97       102\n",
      "          2       0.45      0.74      0.56        87\n",
      "          3       0.86      0.79      0.82        76\n",
      "          4       0.70      0.68      0.69        81\n",
      "          5       0.87      0.88      0.88        86\n",
      "          6       0.58      0.43      0.50       104\n",
      "          7       0.88      0.86      0.87        98\n",
      "          8       0.92      0.87      0.89        92\n",
      "          9       0.89      0.92      0.90        84\n",
      "\n",
      "avg / total       0.79      0.78      0.78       900\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>81</td>\n",
       "      <td>96</td>\n",
       "      <td>141</td>\n",
       "      <td>70</td>\n",
       "      <td>79</td>\n",
       "      <td>87</td>\n",
       "      <td>77</td>\n",
       "      <td>95</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1    2   3   4   5   6   7   8   9  All\n",
       "True                                                   \n",
       "0          61   0   10   4   1   1  12   0   1   0   90\n",
       "1           0  96    5   1   0   0   0   0   0   0  102\n",
       "2           2   0   64   0  10   1  10   0   0   0   87\n",
       "3           4   0    8  60   2   0   2   0   0   0   76\n",
       "4           2   0   13   3  55   0   8   0   0   0   81\n",
       "5           0   0    0   0   0  76   0   7   0   3   86\n",
       "6          12   0   29   1  10   1  45   0   6   0  104\n",
       "7           0   0    3   0   0   4   0  84   0   7   98\n",
       "8           0   0    8   1   1   2   0   0  80   0   92\n",
       "9           0   0    1   0   0   2   0   4   0  77   84\n",
       "All        81  96  141  70  79  87  77  95  87  87  900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = StackedEnsembleClassifierTree.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"StackedEnsembleClassifier DecisionTree\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "report = metrics.classification_report(y_test, y_pred)\n",
    "model_test_f1_comparisons[\"StackedEnsembleClassifier DecisionTree\"] = report.split('\\n')[-2].split('      ')[3]\n",
    "\n",
    "# Print nicer homemade confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "display(pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfrom a cross validation experiment to evaluate the performance of the StackedEnsembleClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 2.0min\n",
      "[CV] ................................................. , total= 2.1min\n",
      "[CV] ................................................. , total= 2.1min\n",
      "[CV] ................................................. , total= 2.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  2.1min remaining:  1.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total= 2.1min\n",
      "[0.78723404 0.75771971 0.74821853 0.74880383 0.77458034]\n",
      "0.7633112896632175  +/-  0.01528929781994985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  2.1min finished\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(StackedEnsembleClassifierTree,X_train_plus_valid, y_train_plus_valid, cv=cv_folds, \\\n",
    "                         n_jobs=-1, verbose = 2)\n",
    "print(scores)\n",
    "print(np.mean(scores), \" +/- \", np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StackedEnsembleClassifierHoldOut with Tree model at Stack Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackedEnsembleHoldOut(base_estimator_duplicates=8,\n",
       "            base_estimator_types=['svm', 'logreg', 'tree'],\n",
       "            stack_layer_classifier_type='tree')"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stackedEnsembleHoldOutTreeModel = StackedEnsembleHoldOut(base_estimator_types = [\"svm\", \"logreg\", \"tree\"], \\\n",
    "                                                         base_estimator_duplicates = 8,\\\n",
    "                                                         stack_layer_classifier_type = \"tree\")\n",
    "stackedEnsembleHoldOutTreeModel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the performance of the ensemble tree on the <b>training set</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.844\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.63      0.72       121\n",
      "          1       0.99      0.96      0.98       142\n",
      "          2       0.86      0.78      0.82       169\n",
      "          3       0.87      0.93      0.89       147\n",
      "          4       0.79      0.82      0.81       147\n",
      "          5       0.98      0.85      0.91       142\n",
      "          6       0.55      0.71      0.62       167\n",
      "          7       0.80      0.97      0.88       149\n",
      "          8       0.97      0.96      0.97       158\n",
      "          9       0.96      0.82      0.88       158\n",
      "\n",
      "avg / total       0.86      0.84      0.85      1500\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>152</td>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>89</td>\n",
       "      <td>139</td>\n",
       "      <td>153</td>\n",
       "      <td>157</td>\n",
       "      <td>151</td>\n",
       "      <td>124</td>\n",
       "      <td>216</td>\n",
       "      <td>180</td>\n",
       "      <td>156</td>\n",
       "      <td>135</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                            \n",
       "0          76    0    2    8    0    0   34    1    0    0   121\n",
       "1           0  137    1    3    0    0    1    0    0    0   142\n",
       "2           2    0  132    2   13    0   20    0    0    0   169\n",
       "3           0    2    0  136    1    0    8    0    0    0   147\n",
       "4           0    0    5    3  120    0   16    2    1    0   147\n",
       "5           0    0    0    0    0  121    5   13    0    3   142\n",
       "6          11    0   13    4   17    0  119    0    3    0   167\n",
       "7           0    0    0    0    0    1    1  144    0    3   149\n",
       "8           0    0    0    1    0    0    4    1  152    0   158\n",
       "9           0    0    0    0    0    2    8   19    0  129   158\n",
       "All        89  139  153  157  151  124  216  180  156  135  1500"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = stackedEnsembleHoldOutTreeModel.predict(X_train)\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_train, y_pred) # , normalize=True, sample_weight=None\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_train, y_pred))\n",
    "# Print nicer homemade confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "display(pd.crosstab(np.array(y_train), y_pred, rownames=['True'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the performance of the ensemble tree on the <b>validation set</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7666666666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.67      0.75        52\n",
      "          1       1.00      0.97      0.98        58\n",
      "          2       0.81      0.64      0.72        69\n",
      "          3       0.66      0.90      0.77        63\n",
      "          4       0.68      0.62      0.65        63\n",
      "          5       0.98      0.74      0.84        54\n",
      "          6       0.39      0.50      0.44        56\n",
      "          7       0.69      0.98      0.81        60\n",
      "          8       0.92      0.89      0.90        73\n",
      "          9       1.00      0.71      0.83        52\n",
      "\n",
      "avg / total       0.80      0.77      0.77       600\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>41</td>\n",
       "      <td>56</td>\n",
       "      <td>54</td>\n",
       "      <td>86</td>\n",
       "      <td>57</td>\n",
       "      <td>41</td>\n",
       "      <td>71</td>\n",
       "      <td>86</td>\n",
       "      <td>71</td>\n",
       "      <td>37</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1   2   3   4   5   6   7   8   9  All\n",
       "True                                                  \n",
       "0          35   0   0   6   0   0  10   1   0   0   52\n",
       "1           0  56   0   0   0   0   1   0   1   0   58\n",
       "2           0   0  44   1  10   0  14   0   0   0   69\n",
       "3           1   0   1  57   3   0   1   0   0   0   63\n",
       "4           0   0   3  11  39   0  10   0   0   0   63\n",
       "5           0   0   0   1   0  40   3   9   1   0   54\n",
       "6           5   0   6   8   4   0  28   1   4   0   56\n",
       "7           0   0   0   0   0   1   0  59   0   0   60\n",
       "8           0   0   0   2   1   0   3   2  65   0   73\n",
       "9           0   0   0   0   0   0   1  14   0  37   52\n",
       "All        41  56  54  86  57  41  71  86  71  37  600"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = stackedEnsembleHoldOutTreeModel.predict(X_valid)\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "model_valid_accuracy_comparisons[\"StackedEnsembleHoldOutClassifier DecisionTree\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "report = metrics.classification_report(y_valid, y_pred)\n",
    "model_valid_f1_comparisons[\"StackedEnsembleHoldOutClassifier DecisionTree\"] = report.split('\\n')[-2].split('      ')[3]\n",
    "\n",
    "# Print nicer homemade confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "display(pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the performance of the ensemble tree on the <b>test set</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7577777777777778\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.53      0.66        90\n",
      "          1       1.00      0.93      0.96       102\n",
      "          2       0.68      0.62      0.65        87\n",
      "          3       0.68      0.91      0.78        76\n",
      "          4       0.68      0.69      0.69        81\n",
      "          5       0.90      0.83      0.86        86\n",
      "          6       0.41      0.53      0.46       104\n",
      "          7       0.74      0.89      0.81        98\n",
      "          8       0.97      0.93      0.95        92\n",
      "          9       0.90      0.73      0.80        84\n",
      "\n",
      "avg / total       0.78      0.76      0.76       900\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>56</td>\n",
       "      <td>95</td>\n",
       "      <td>79</td>\n",
       "      <td>101</td>\n",
       "      <td>82</td>\n",
       "      <td>79</td>\n",
       "      <td>134</td>\n",
       "      <td>117</td>\n",
       "      <td>89</td>\n",
       "      <td>68</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1   2    3   4   5    6    7   8   9  All\n",
       "True                                                     \n",
       "0          48   0   1   12   1   0   27    1   0   0   90\n",
       "1           0  95   2    3   0   0    2    0   0   0  102\n",
       "2           0   0  54    0  10   0   23    0   0   0   87\n",
       "3           0   0   2   69   1   0    4    0   0   0   76\n",
       "4           0   0   2   10  56   0   13    0   0   0   81\n",
       "5           0   0   0    0   0  71    4    9   0   2   86\n",
       "6           8   0  17    5  14   0   55    2   3   0  104\n",
       "7           0   0   0    0   0   6    0   87   0   5   98\n",
       "8           0   0   1    2   0   0    3    0  86   0   92\n",
       "9           0   0   0    0   0   2    3   18   0  61   84\n",
       "All        56  95  79  101  82  79  134  117  89  68  900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = stackedEnsembleHoldOutTreeModel.predict(X_test)\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"StackedEnsembleHoldOutClassifier DecisionTree\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "report = metrics.classification_report(y_test, y_pred)\n",
    "model_test_f1_comparisons[\"StackedEnsembleHoldOutClassifier DecisionTree\"] = report.split('\\n')[-2].split('      ')[3]\n",
    "\n",
    "# Print nicer homemade confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "display(pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfrom a cross validation experiment to evaluate the performance of the StackedEnsembleHoldOutClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total=  59.1s\n",
      "[CV] ................................................. , total= 1.0min\n",
      "[CV] ................................................. , total= 1.0min\n",
      "[CV] ................................................. , total= 1.0min\n",
      "[CV] ................................................. , total= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  1.0min remaining:   41.3s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.74231678 0.74821853 0.72446556 0.76555024 0.7529976 ]\n",
      "0.746709742306716  +/-  0.013497257032686009\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(stackedEnsembleHoldOutTreeModel,X_train_plus_valid, y_train_plus_valid, cv=cv_folds, \\\n",
    "                         n_jobs=-1, verbose = 2)\n",
    "print(scores)\n",
    "print(np.mean(scores), \" +/- \", np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StackedEnsemble kFold classifier  with Tree model at Stack Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackedEnsembleKFold(base_estimator_duplicates=8,\n",
       "           base_estimator_types=['svm', 'logreg', 'tree'],\n",
       "           stack_layer_classifier_type='tree', training_folds=4)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stackedEnsembleKFoldTreeModel = StackedEnsembleKFold(base_estimator_types = [\"svm\", \"logreg\", \"tree\"],\\\n",
    "                                                     base_estimator_duplicates = 8, \\\n",
    "                                                     stack_layer_classifier_type = \"tree\")\n",
    "stackedEnsembleKFoldTreeModel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the performance of the ensemble tree on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.816\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.64      0.66       121\n",
      "          1       1.00      0.94      0.97       142\n",
      "          2       0.69      0.82      0.75       169\n",
      "          3       0.67      0.83      0.74       147\n",
      "          4       0.75      0.82      0.78       147\n",
      "          5       0.90      0.87      0.88       142\n",
      "          6       0.62      0.42      0.50       167\n",
      "          7       0.90      0.92      0.91       149\n",
      "          8       0.97      0.99      0.98       158\n",
      "          9       0.96      0.92      0.94       158\n",
      "\n",
      "avg / total       0.82      0.82      0.81      1500\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>6.0</th>\n",
       "      <th>7.0</th>\n",
       "      <th>8.0</th>\n",
       "      <th>9.0</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>134</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>114</td>\n",
       "      <td>134</td>\n",
       "      <td>199</td>\n",
       "      <td>181</td>\n",
       "      <td>159</td>\n",
       "      <td>136</td>\n",
       "      <td>112</td>\n",
       "      <td>152</td>\n",
       "      <td>161</td>\n",
       "      <td>152</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  0.0  1.0  2.0  3.0  4.0  5.0  6.0  7.0  8.0  9.0   All\n",
       "True                                                             \n",
       "0           78    0    6   11    3    0   23    0    0    0   121\n",
       "1            1  134    1    6    0    0    0    0    0    0   142\n",
       "2            6    0  138    3   13    0    9    0    0    0   169\n",
       "3           21    0    2  122    1    0    1    0    0    0   147\n",
       "4            2    0   11    5  120    0    8    0    1    0   147\n",
       "5            0    0    0    9    0  123    0    6    0    4   142\n",
       "6            6    0   41   24   22    0   70    0    4    0   167\n",
       "7            0    0    0    0    0   10    0  137    0    2   149\n",
       "8            0    0    0    1    0    0    1    0  156    0   158\n",
       "9            0    0    0    0    0    3    0    9    0  146   158\n",
       "All        114  134  199  181  159  136  112  152  161  152  1500"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = stackedEnsembleKFoldTreeModel.predict(X_train)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_train, y_pred) # , normalize=True, sample_weight=None\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_train, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "display(pd.crosstab(np.array(y_train), y_pred, rownames=['True'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the performance of the ensemble tree on the <b>validation set</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7466666666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.65      0.62        52\n",
      "          1       1.00      0.88      0.94        58\n",
      "          2       0.69      0.72      0.71        69\n",
      "          3       0.60      0.78      0.68        63\n",
      "          4       0.66      0.68      0.67        63\n",
      "          5       0.87      0.74      0.80        54\n",
      "          6       0.47      0.30      0.37        56\n",
      "          7       0.77      0.90      0.83        60\n",
      "          8       0.89      0.92      0.91        73\n",
      "          9       0.93      0.83      0.88        52\n",
      "\n",
      "avg / total       0.75      0.75      0.74       600\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>6.0</th>\n",
       "      <th>7.0</th>\n",
       "      <th>8.0</th>\n",
       "      <th>9.0</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>58</td>\n",
       "      <td>51</td>\n",
       "      <td>72</td>\n",
       "      <td>81</td>\n",
       "      <td>65</td>\n",
       "      <td>46</td>\n",
       "      <td>36</td>\n",
       "      <td>70</td>\n",
       "      <td>75</td>\n",
       "      <td>46</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  0.0  1.0  2.0  3.0  4.0  5.0  6.0  7.0  8.0  9.0  All\n",
       "True                                                            \n",
       "0           34    0    1    7    0    0    9    0    1    0   52\n",
       "1            2   51    1    3    0    0    0    0    1    0   58\n",
       "2            1    0   50    2   11    0    5    0    0    0   69\n",
       "3            7    0    2   49    1    0    3    0    1    0   63\n",
       "4            3    0    9    7   43    0    1    0    0    0   63\n",
       "5            1    0    0    3    0   40    0    8    1    1   54\n",
       "6            8    0    9   10    8    0   17    0    4    0   56\n",
       "7            0    0    0    0    0    4    0   54    0    2   60\n",
       "8            1    0    0    0    2    1    1    1   67    0   73\n",
       "9            1    0    0    0    0    1    0    7    0   43   52\n",
       "All         58   51   72   81   65   46   36   70   75   46  600"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = stackedEnsembleKFoldTreeModel.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "model_valid_accuracy_comparisons[\"StackedEnsembleKFoldClassifier DecisionTree\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "report = metrics.classification_report(y_valid, y_pred)\n",
    "model_valid_f1_comparisons[\"StackedEnsembleKFoldClassifier DecisionTree\"] = report.split('\\n')[-2].split('      ')[3]\n",
    "\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "display(pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the performance of the ensemble tree on the <b>test set</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7455555555555555\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.53      0.56        90\n",
      "          1       0.99      0.86      0.92       102\n",
      "          2       0.63      0.69      0.66        87\n",
      "          3       0.55      0.82      0.66        76\n",
      "          4       0.59      0.72      0.64        81\n",
      "          5       0.90      0.80      0.85        86\n",
      "          6       0.48      0.28      0.35       104\n",
      "          7       0.90      0.91      0.90        98\n",
      "          8       0.93      0.99      0.96        92\n",
      "          9       0.89      0.92      0.90        84\n",
      "\n",
      "avg / total       0.75      0.75      0.74       900\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>6.0</th>\n",
       "      <th>7.0</th>\n",
       "      <th>8.0</th>\n",
       "      <th>9.0</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>82</td>\n",
       "      <td>89</td>\n",
       "      <td>95</td>\n",
       "      <td>113</td>\n",
       "      <td>99</td>\n",
       "      <td>77</td>\n",
       "      <td>61</td>\n",
       "      <td>99</td>\n",
       "      <td>98</td>\n",
       "      <td>87</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  0.0  1.0  2.0  3.0  4.0  5.0  6.0  7.0  8.0  9.0  All\n",
       "True                                                            \n",
       "0           48    0    2   16    0    1   22    0    1    0   90\n",
       "1            1   88    2   11    0    0    0    0    0    0  102\n",
       "2            5    0   60    3   13    0    6    0    0    0   87\n",
       "3            9    0    2   62    3    0    0    0    0    0   76\n",
       "4            5    1    7    6   58    0    4    0    0    0   81\n",
       "5            0    0    0    6    0   69    0    6    0    5   86\n",
       "6           14    0   21    9   25    0   29    0    6    0  104\n",
       "7            0    0    0    0    0    4    0   89    0    5   98\n",
       "8            0    0    1    0    0    0    0    0   91    0   92\n",
       "9            0    0    0    0    0    3    0    4    0   77   84\n",
       "All         82   89   95  113   99   77   61   99   98   87  900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = stackedEnsembleKFoldTreeModel.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"StackedEnsembleKFoldClassifier DecisionTree\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "report = metrics.classification_report(y_test, y_pred)\n",
    "model_test_f1_comparisons[\"StackedEnsembleKFoldClassifier DecisionTree\"] = report.split('\\n')[-2].split('      ')[3]\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "display(pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfrom a cross validation experiment to evaluate the performance of the StackedEnsembleKFoldClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 6.3min\n",
      "[CV] ................................................. , total= 6.4min\n",
      "[CV] ................................................. , total= 6.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  6.4min remaining:  4.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total= 6.4min\n",
      "[CV] ................................................. , total= 6.5min\n",
      "[0.76595745 0.73871734 0.72921615 0.72966507 0.69304556]\n",
      "0.7313203147628934  +/-  0.0233519626775764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  6.5min finished\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(stackedEnsembleKFoldTreeModel,X_train_plus_valid, y_train_plus_valid, cv=cv_folds, \\\n",
    "                         n_jobs=-1, verbose = 2)\n",
    "print(scores)\n",
    "print(np.mean(scores), \" +/- \", np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Summary of results</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Accuracy-Validation Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>StackedEnsembleClassifier LogisticRegression</td>\n",
       "      <td>0.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>StackedEnsembleHoldOutClassifier LogisticRegre...</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>StackedEnsembleKFoldClassifier LogisticRegression</td>\n",
       "      <td>0.811667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>StackedEnsembleClassifier DecisionTree</td>\n",
       "      <td>0.776667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>StackedEnsembleHoldOutClassifier DecisionTree</td>\n",
       "      <td>0.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>StackedEnsembleKFoldClassifier DecisionTree</td>\n",
       "      <td>0.746667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Model Name  Accuracy-Validation Data\n",
       "0       StackedEnsembleClassifier LogisticRegression                  0.810000\n",
       "1  StackedEnsembleHoldOutClassifier LogisticRegre...                  0.800000\n",
       "2  StackedEnsembleKFoldClassifier LogisticRegression                  0.811667\n",
       "3             StackedEnsembleClassifier DecisionTree                  0.776667\n",
       "4      StackedEnsembleHoldOutClassifier DecisionTree                  0.766667\n",
       "5        StackedEnsembleKFoldClassifier DecisionTree                  0.746667"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(model_valid_accuracy_comparisons.items()), columns=['Model Name', 'Accuracy-Validation Data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Accuracy of Test Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>StackedEnsembleClassifier LogisticRegression</td>\n",
       "      <td>0.804444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>StackedEnsembleHoldOutClassifier LogisticRegre...</td>\n",
       "      <td>0.803333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>StackedEnsembleKFoldClassifier LogisticRegression</td>\n",
       "      <td>0.797778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>StackedEnsembleClassifier DecisionTree</td>\n",
       "      <td>0.775556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>StackedEnsembleHoldOutClassifier DecisionTree</td>\n",
       "      <td>0.757778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>StackedEnsembleKFoldClassifier DecisionTree</td>\n",
       "      <td>0.745556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Model Name  Accuracy of Test Data\n",
       "0       StackedEnsembleClassifier LogisticRegression               0.804444\n",
       "1  StackedEnsembleHoldOutClassifier LogisticRegre...               0.803333\n",
       "2  StackedEnsembleKFoldClassifier LogisticRegression               0.797778\n",
       "3             StackedEnsembleClassifier DecisionTree               0.775556\n",
       "4      StackedEnsembleHoldOutClassifier DecisionTree               0.757778\n",
       "5        StackedEnsembleKFoldClassifier DecisionTree               0.745556"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(model_test_accuracy_comparisons.items()), columns=['Model Name', 'Accuracy of Test Data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Average F1 score of Validation Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>StackedEnsembleClassifier LogisticRegression</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>StackedEnsembleHoldOutClassifier LogisticRegre...</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>StackedEnsembleKFoldClassifier LogisticRegression</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>StackedEnsembleClassifier DecisionTree</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>StackedEnsembleHoldOutClassifier DecisionTree</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>StackedEnsembleKFoldClassifier DecisionTree</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Model Name  \\\n",
       "0       StackedEnsembleClassifier LogisticRegression   \n",
       "1  StackedEnsembleHoldOutClassifier LogisticRegre...   \n",
       "2  StackedEnsembleKFoldClassifier LogisticRegression   \n",
       "3             StackedEnsembleClassifier DecisionTree   \n",
       "4      StackedEnsembleHoldOutClassifier DecisionTree   \n",
       "5        StackedEnsembleKFoldClassifier DecisionTree   \n",
       "\n",
       "  Average F1 score of Validation Data  \n",
       "0                                0.81  \n",
       "1                                0.80  \n",
       "2                                0.81  \n",
       "3                                0.78  \n",
       "4                                0.77  \n",
       "5                                0.74  "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(model_valid_f1_comparisons.items()), columns=['Model Name', 'Average F1 score of Validation Data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Average F1 score of Test Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>StackedEnsembleClassifier LogisticRegression</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>StackedEnsembleHoldOutClassifier LogisticRegre...</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>StackedEnsembleKFoldClassifier LogisticRegression</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>StackedEnsembleClassifier DecisionTree</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>StackedEnsembleHoldOutClassifier DecisionTree</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>StackedEnsembleKFoldClassifier DecisionTree</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Model Name  \\\n",
       "0       StackedEnsembleClassifier LogisticRegression   \n",
       "1  StackedEnsembleHoldOutClassifier LogisticRegre...   \n",
       "2  StackedEnsembleKFoldClassifier LogisticRegression   \n",
       "3             StackedEnsembleClassifier DecisionTree   \n",
       "4      StackedEnsembleHoldOutClassifier DecisionTree   \n",
       "5        StackedEnsembleKFoldClassifier DecisionTree   \n",
       "\n",
       "  Average F1 score of Test Data  \n",
       "0                          0.80  \n",
       "1                          0.80  \n",
       "2                          0.79  \n",
       "3                          0.78  \n",
       "4                          0.76  \n",
       "5                          0.74  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(model_test_f1_comparisons.items()), columns=['Model Name', 'Average F1 score of Test Data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Observation</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above tables, we can see that Logistic Regression model at stack layer works better than Decision tree as both accuracy and average F1 measure score are higher for StackedEnsembleModel with Logistic Regression model at stack layer. If we look at the accuracy on validation data, then StackedEnsembleKFoldClassifier is giving us slightly better results. But if we look at the accuracy on test data, then StackedEnsembleClassifier in which we are using entire training data to generate the predictions is giving us slightly better score. Since on test data, we are getting good accuracy, so there is no overfitting happening. To avoid overfitting, we can use KFold approach. If we look at the F1 score of all the models which has logistic regression model at stack layer, then we can see that there is only slight variation in the result. KFold can reduce the chance of overfitting but it is computationally more expensive. As we can training the model multiple times on different folds of data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Comparing the Performance of Different Stack Layer Approaches with  More Standard Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_folds=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tree = tree.DecisionTreeClassifier(criterion=\"entropy\", min_samples_split = 200)\n",
    "my_tree = my_tree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the performance of the decision tree on the <b>validation set</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7116666666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.83      0.81        52\n",
      "          1       0.96      0.86      0.91        58\n",
      "          2       0.75      0.71      0.73        69\n",
      "          3       0.52      0.73      0.61        63\n",
      "          4       0.58      0.52      0.55        63\n",
      "          5       0.62      0.65      0.64        54\n",
      "          6       0.62      0.38      0.47        56\n",
      "          7       0.70      0.80      0.74        60\n",
      "          8       0.88      0.79      0.83        73\n",
      "          9       0.75      0.85      0.79        52\n",
      "\n",
      "avg / total       0.72      0.71      0.71       600\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>54</td>\n",
       "      <td>52</td>\n",
       "      <td>65</td>\n",
       "      <td>88</td>\n",
       "      <td>57</td>\n",
       "      <td>56</td>\n",
       "      <td>34</td>\n",
       "      <td>69</td>\n",
       "      <td>66</td>\n",
       "      <td>59</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1   2   3   4   5   6   7   8   9  All\n",
       "True                                                  \n",
       "0          43   0   1   7   0   0   0   0   1   0   52\n",
       "1           0  50   0   6   0   0   1   0   1   0   58\n",
       "2           0   0  49   1  16   0   3   0   0   0   69\n",
       "3           1   1   3  46   0  12   0   0   0   0   63\n",
       "4           0   0   8  15  33   0   7   0   0   0   63\n",
       "5           0   0   0   2   0  35   0  10   0   7   54\n",
       "6          10   0   3   9   6   1  21   0   6   0   56\n",
       "7           0   0   0   0   0   5   0  48   0   7   60\n",
       "8           0   1   1   1   1   2   2   6  58   1   73\n",
       "9           0   0   0   1   1   1   0   5   0  44   52\n",
       "All        54  52  65  88  57  56  34  69  66  59  600"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tree.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "model_valid_accuracy_comparisons[\"Single Decision Tree\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "report = metrics.classification_report(y_valid, y_pred)\n",
    "model_valid_f1_comparisons[\"Single Decision Tree\"] = report.split('\\n')[-2].split('      ')[3]\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True, dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the performance of the decision tree on the <b>test set</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6711111111111111\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.70      0.71        90\n",
      "          1       0.92      0.80      0.86       102\n",
      "          2       0.54      0.66      0.59        87\n",
      "          3       0.47      0.79      0.59        76\n",
      "          4       0.56      0.47      0.51        81\n",
      "          5       0.68      0.49      0.57        86\n",
      "          6       0.54      0.28      0.37       104\n",
      "          7       0.78      0.83      0.80        98\n",
      "          8       0.84      0.83      0.83        92\n",
      "          9       0.68      0.90      0.78        84\n",
      "\n",
      "avg / total       0.68      0.67      0.66       900\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>88</td>\n",
       "      <td>89</td>\n",
       "      <td>105</td>\n",
       "      <td>128</td>\n",
       "      <td>68</td>\n",
       "      <td>62</td>\n",
       "      <td>54</td>\n",
       "      <td>104</td>\n",
       "      <td>91</td>\n",
       "      <td>111</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1    2    3   4   5   6    7   8    9  All\n",
       "True                                                      \n",
       "0          63   1    4   17   1   0   0    0   4    0   90\n",
       "1           0  82    4   15   0   1   0    0   0    0  102\n",
       "2           2   1   57    1  17   1   7    0   1    0   87\n",
       "3           2   1    3   60   0   6   2    0   1    1   76\n",
       "4           1   1    9   16  38   0  16    0   0    0   81\n",
       "5           0   2    0    0   0  42   0   17   4   21   86\n",
       "6          20   0   27   13  11   0  29    0   4    0  104\n",
       "7           0   0    0    0   0   3   0   81   1   13   98\n",
       "8           0   1    1    5   1   7   0    1  76    0   92\n",
       "9           0   0    0    1   0   2   0    5   0   76   84\n",
       "All        88  89  105  128  68  62  54  104  91  111  900"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tree.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"Decision Tree\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "report = metrics.classification_report(y_test, y_pred)\n",
    "model_test_f1_comparisons[\"Decision Tree\"] = report.split('\\n')[-2].split('      ')[3]\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True, dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning the Performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "[CV] criterion=gini, max_depth=3, min_samples_split=200 ..............\n",
      "[CV]  criterion=gini, max_depth=3, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=gini, max_depth=3, min_samples_split=200 ..............\n",
      "[CV]  criterion=gini, max_depth=3, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=gini, max_depth=3, min_samples_split=200 ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=gini, max_depth=3, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=gini, max_depth=3, min_samples_split=200 ..............\n",
      "[CV]  criterion=gini, max_depth=3, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=gini, max_depth=3, min_samples_split=200 ..............\n",
      "[CV]  criterion=gini, max_depth=3, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=gini, max_depth=6, min_samples_split=200 ..............\n",
      "[CV]  criterion=gini, max_depth=6, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=6, min_samples_split=200 ..............\n",
      "[CV]  criterion=gini, max_depth=6, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=6, min_samples_split=200 ..............\n",
      "[CV]  criterion=gini, max_depth=6, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=6, min_samples_split=200 ..............\n",
      "[CV]  criterion=gini, max_depth=6, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=6, min_samples_split=200 ..............\n",
      "[CV]  criterion=gini, max_depth=6, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=9, min_samples_split=200 ..............\n",
      "[CV]  criterion=gini, max_depth=9, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=9, min_samples_split=200 ..............\n",
      "[CV]  criterion=gini, max_depth=9, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=9, min_samples_split=200 ..............\n",
      "[CV]  criterion=gini, max_depth=9, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=9, min_samples_split=200 ..............\n",
      "[CV]  criterion=gini, max_depth=9, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=9, min_samples_split=200 ..............\n",
      "[CV]  criterion=gini, max_depth=9, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=12, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=12, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=12, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=12, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=12, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=12, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=12, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=12, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=12, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=12, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=15, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=15, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=15, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=15, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=15, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=18, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=18, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=18, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=18, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=18, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=18, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=18, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=18, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=18, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=18, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=21, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=21, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=21, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=21, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=21, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=21, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=21, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=21, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=21, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=21, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=24, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=24, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=24, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=24, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=24, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=24, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=24, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=24, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=24, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=24, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=27, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=27, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=27, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=27, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=27, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=27, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=27, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=27, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=27, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=27, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=30, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=30, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=30, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=30, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=30, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=30, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=30, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=30, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=30, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=30, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=33, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=33, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=33, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=33, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=33, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=33, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=33, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=33, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=33, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=33, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=36, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=36, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=36, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=36, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=36, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=36, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=36, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=36, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=36, min_samples_split=200 .............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=gini, max_depth=36, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=39, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=39, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=39, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=39, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=39, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=39, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=39, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=39, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=39, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=39, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=42, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=42, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=42, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=42, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=42, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=42, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=42, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=42, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=42, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=42, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=45, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=45, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=45, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=45, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=45, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=45, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=45, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=45, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=45, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=45, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=48, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=48, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=48, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=48, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=48, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=48, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=48, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=48, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=48, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=48, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=entropy, max_depth=3, min_samples_split=200 ...........\n",
      "[CV]  criterion=entropy, max_depth=3, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=entropy, max_depth=3, min_samples_split=200 ...........\n",
      "[CV]  criterion=entropy, max_depth=3, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=entropy, max_depth=3, min_samples_split=200 ...........\n",
      "[CV]  criterion=entropy, max_depth=3, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=entropy, max_depth=3, min_samples_split=200 ...........\n",
      "[CV]  criterion=entropy, max_depth=3, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=entropy, max_depth=3, min_samples_split=200 ...........\n",
      "[CV]  criterion=entropy, max_depth=3, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=entropy, max_depth=6, min_samples_split=200 ...........\n",
      "[CV]  criterion=entropy, max_depth=6, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=6, min_samples_split=200 ...........\n",
      "[CV]  criterion=entropy, max_depth=6, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=6, min_samples_split=200 ...........\n",
      "[CV]  criterion=entropy, max_depth=6, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=6, min_samples_split=200 ...........\n",
      "[CV]  criterion=entropy, max_depth=6, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=6, min_samples_split=200 ...........\n",
      "[CV]  criterion=entropy, max_depth=6, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=9, min_samples_split=200 ...........\n",
      "[CV]  criterion=entropy, max_depth=9, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=9, min_samples_split=200 ...........\n",
      "[CV]  criterion=entropy, max_depth=9, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=9, min_samples_split=200 ...........\n",
      "[CV]  criterion=entropy, max_depth=9, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=9, min_samples_split=200 ...........\n",
      "[CV]  criterion=entropy, max_depth=9, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=9, min_samples_split=200 ...........\n",
      "[CV]  criterion=entropy, max_depth=9, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=12, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=12, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=12, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=12, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=12, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=12, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=12, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=12, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=12, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=12, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=18, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=18, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=18, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=18, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=18, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=18, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=18, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=18, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=18, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=18, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=21, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=21, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=21, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=21, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=21, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=21, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=21, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=21, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=21, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=21, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=24, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=24, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=24, min_samples_split=200 ..........\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=entropy, max_depth=24, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=24, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=24, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=24, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=24, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=24, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=24, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=27, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=27, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=27, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=27, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=27, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=27, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=27, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=27, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=27, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=27, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=30, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=30, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=30, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=30, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=30, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=30, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=30, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=30, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=30, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=30, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=33, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=33, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=33, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=33, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=33, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=33, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=33, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=33, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=33, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=33, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=36, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=36, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=36, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=36, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=36, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=36, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=36, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=36, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=36, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=36, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=39, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=39, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=39, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=39, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=39, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=39, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=39, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=39, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=39, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=39, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=42, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=42, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=42, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=42, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=42, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=42, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=42, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=42, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=42, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=42, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=45, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=45, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=45, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=45, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=45, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=45, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=45, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=45, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=45, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=45, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=48, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=48, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=48, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=48, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=48, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=48, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=48, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=48, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=48, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=48, min_samples_split=200, total=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 160 out of 160 | elapsed:   37.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'max_depth': 21, 'min_samples_split': 200}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6761904761904762"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.11311021, 0.17271771, 0.18050618, 0.17846003, 0.17761655,\n",
       "        0.17691865, 0.17657061, 0.18004389, 0.17690187, 0.1770618 ,\n",
       "        0.17777519, 0.17618308, 0.17677636, 0.17518082, 0.17646694,\n",
       "        0.1753015 , 0.19392881, 0.29434667, 0.29207969, 0.28598042,\n",
       "        0.28737588, 0.29473729, 0.29438453, 0.29603415, 0.29593945,\n",
       "        0.29521613, 0.28423162, 0.29412127, 0.28557544, 0.28500309,\n",
       "        0.28603296, 0.28279877]),\n",
       " 'std_fit_time': array([0.00274158, 0.00457214, 0.00462336, 0.00509475, 0.00350961,\n",
       "        0.00463287, 0.00490888, 0.00698701, 0.00392225, 0.00506535,\n",
       "        0.00648728, 0.0048875 , 0.00297369, 0.00413448, 0.00567252,\n",
       "        0.0045888 , 0.00272765, 0.01686156, 0.01613557, 0.01295277,\n",
       "        0.01418961, 0.01641193, 0.0164763 , 0.01831643, 0.01400206,\n",
       "        0.01459445, 0.01407259, 0.02216861, 0.01503328, 0.01259411,\n",
       "        0.01629564, 0.01567783]),\n",
       " 'mean_score_time': array([0.00078506, 0.00063753, 0.00062413, 0.00062938, 0.00063195,\n",
       "        0.00061369, 0.00064535, 0.00062609, 0.00061941, 0.00061378,\n",
       "        0.00062265, 0.00063009, 0.00064278, 0.00062079, 0.00063   ,\n",
       "        0.00061707, 0.00069957, 0.00064344, 0.00060983, 0.00061588,\n",
       "        0.00062938, 0.00063205, 0.00067744, 0.00062447, 0.00066495,\n",
       "        0.00062099, 0.00061269, 0.00062108, 0.0006331 , 0.00067949,\n",
       "        0.00068989, 0.00062985]),\n",
       " 'std_score_time': array([2.07907639e-04, 1.58987834e-05, 1.37262858e-05, 2.37507989e-05,\n",
       "        1.60330778e-05, 5.83029712e-06, 4.27726918e-05, 2.74179293e-05,\n",
       "        7.80470420e-06, 1.20079678e-05, 1.38378110e-05, 2.02211566e-05,\n",
       "        4.66255557e-05, 2.42388105e-05, 9.77760377e-06, 9.61911864e-06,\n",
       "        1.02021803e-04, 1.07255507e-05, 9.17140216e-06, 1.37899130e-05,\n",
       "        1.80042497e-05, 1.94348437e-05, 9.21435959e-05, 2.33208960e-05,\n",
       "        3.05659685e-05, 8.02815932e-06, 1.01571911e-05, 1.05066607e-05,\n",
       "        3.05133310e-05, 6.64140191e-05, 6.26404334e-05, 1.36798257e-05]),\n",
       " 'param_criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42,\n",
       "                    45, 48, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36,\n",
       "                    39, 42, 45, 48],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_split': masked_array(data=[200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200,\n",
       "                    200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200,\n",
       "                    200, 200, 200, 200, 200, 200, 200, 200, 200, 200],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 6, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 9, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 12, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 18, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 21, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 24, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 27, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 33, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 36, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 39, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 42, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 45, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 48, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 6, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 9, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 12, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 18, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 21, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 24, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 27, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 33, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 36, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 39, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 42, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 45, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 48, 'min_samples_split': 200}],\n",
       " 'split0_test_score': array([0.5106383 , 0.68321513, 0.70449173, 0.70449173, 0.70449173,\n",
       "        0.70449173, 0.70449173, 0.70449173, 0.70449173, 0.70449173,\n",
       "        0.70449173, 0.70449173, 0.70449173, 0.70449173, 0.70449173,\n",
       "        0.70449173, 0.53900709, 0.72104019, 0.72104019, 0.72104019,\n",
       "        0.72104019, 0.71867612, 0.72104019, 0.72104019, 0.72104019,\n",
       "        0.72104019, 0.72104019, 0.71867612, 0.71867612, 0.71867612,\n",
       "        0.71867612, 0.71867612]),\n",
       " 'split1_test_score': array([0.47268409, 0.65558195, 0.67220903, 0.67220903, 0.67220903,\n",
       "        0.67220903, 0.67220903, 0.67220903, 0.67220903, 0.67220903,\n",
       "        0.67220903, 0.67220903, 0.67220903, 0.67220903, 0.67220903,\n",
       "        0.67220903, 0.51306413, 0.67458432, 0.67458432, 0.67458432,\n",
       "        0.67458432, 0.67458432, 0.67458432, 0.67458432, 0.67458432,\n",
       "        0.67458432, 0.67458432, 0.67458432, 0.67458432, 0.67458432,\n",
       "        0.67458432, 0.67458432]),\n",
       " 'split2_test_score': array([0.4608076 , 0.63657957, 0.64845606, 0.64845606, 0.64845606,\n",
       "        0.64608076, 0.64845606, 0.64845606, 0.64845606, 0.64845606,\n",
       "        0.64845606, 0.64845606, 0.64845606, 0.64845606, 0.64845606,\n",
       "        0.64845606, 0.52731591, 0.66745843, 0.66745843, 0.66745843,\n",
       "        0.66745843, 0.66745843, 0.66983373, 0.66745843, 0.66745843,\n",
       "        0.66745843, 0.66745843, 0.66745843, 0.66745843, 0.66745843,\n",
       "        0.66983373, 0.66745843]),\n",
       " 'split3_test_score': array([0.48803828, 0.67942584, 0.68421053, 0.68421053, 0.68421053,\n",
       "        0.68421053, 0.68421053, 0.68421053, 0.68421053, 0.68421053,\n",
       "        0.68421053, 0.68421053, 0.68421053, 0.68421053, 0.68421053,\n",
       "        0.68421053, 0.5215311 , 0.66985646, 0.66985646, 0.66985646,\n",
       "        0.66985646, 0.66985646, 0.66985646, 0.66985646, 0.66985646,\n",
       "        0.66985646, 0.66985646, 0.66985646, 0.66985646, 0.66985646,\n",
       "        0.66985646, 0.66985646]),\n",
       " 'split4_test_score': array([0.45083933, 0.62589928, 0.63788969, 0.63788969, 0.63788969,\n",
       "        0.63788969, 0.63788969, 0.63788969, 0.63788969, 0.63788969,\n",
       "        0.63788969, 0.63788969, 0.63788969, 0.63788969, 0.63788969,\n",
       "        0.63788969, 0.50839329, 0.64508393, 0.64508393, 0.64508393,\n",
       "        0.64508393, 0.64508393, 0.64508393, 0.64508393, 0.64508393,\n",
       "        0.64508393, 0.64508393, 0.64508393, 0.64508393, 0.64508393,\n",
       "        0.64508393, 0.64508393]),\n",
       " 'mean_test_score': array([0.47666667, 0.65619048, 0.66952381, 0.66952381, 0.66952381,\n",
       "        0.66904762, 0.66952381, 0.66952381, 0.66952381, 0.66952381,\n",
       "        0.66952381, 0.66952381, 0.66952381, 0.66952381, 0.66952381,\n",
       "        0.66952381, 0.52190476, 0.67571429, 0.67571429, 0.67571429,\n",
       "        0.67571429, 0.6752381 , 0.67619048, 0.67571429, 0.67571429,\n",
       "        0.67571429, 0.67571429, 0.6752381 , 0.6752381 , 0.6752381 ,\n",
       "        0.67571429, 0.6752381 ]),\n",
       " 'std_test_score': array([0.02107751, 0.02267041, 0.02404939, 0.02404939, 0.02404939,\n",
       "        0.02448146, 0.02404939, 0.02404939, 0.02404939, 0.02404939,\n",
       "        0.02404939, 0.02404939, 0.02404939, 0.02404939, 0.02404939,\n",
       "        0.02404939, 0.01080432, 0.02491739, 0.02491739, 0.02491739,\n",
       "        0.02491739, 0.02405426, 0.02477737, 0.02491739, 0.02491739,\n",
       "        0.02491739, 0.02491739, 0.02405426, 0.02405426, 0.02405426,\n",
       "        0.02391867, 0.02405426]),\n",
       " 'rank_test_score': array([32, 30, 16, 16, 16, 29, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 31,\n",
       "         2,  2,  2,  2, 11,  1,  2,  2,  2,  2, 11, 11, 11,  2, 11],\n",
       "       dtype=int32),\n",
       " 'split0_train_score': array([0.51460942, 0.68753727, 0.70542636, 0.70542636, 0.70542636,\n",
       "        0.70542636, 0.70542636, 0.70542636, 0.70542636, 0.70542636,\n",
       "        0.70542636, 0.70542636, 0.70542636, 0.70542636, 0.70542636,\n",
       "        0.70542636, 0.54025045, 0.71735242, 0.71735242, 0.71735242,\n",
       "        0.71735242, 0.71735242, 0.71735242, 0.71735242, 0.71735242,\n",
       "        0.71735242, 0.71735242, 0.71735242, 0.71735242, 0.71735242,\n",
       "        0.71735242, 0.71735242]),\n",
       " 'split1_train_score': array([0.50268017, 0.69982132, 0.72066706, 0.72066706, 0.72066706,\n",
       "        0.72066706, 0.72066706, 0.72066706, 0.72066706, 0.72066706,\n",
       "        0.72066706, 0.72066706, 0.72066706, 0.72066706, 0.72066706,\n",
       "        0.72066706, 0.54556284, 0.71947588, 0.71947588, 0.71947588,\n",
       "        0.71947588, 0.71947588, 0.71947588, 0.71947588, 0.71947588,\n",
       "        0.71947588, 0.71947588, 0.71947588, 0.71947588, 0.71947588,\n",
       "        0.71947588, 0.71947588]),\n",
       " 'split2_train_score': array([0.51935676, 0.72781418, 0.73734366, 0.73734366, 0.73734366,\n",
       "        0.73734366, 0.73734366, 0.73734366, 0.73734366, 0.73734366,\n",
       "        0.73734366, 0.73734366, 0.73734366, 0.73734366, 0.73734366,\n",
       "        0.73734366, 0.53424658, 0.74389518, 0.74389518, 0.74389518,\n",
       "        0.74389518, 0.74389518, 0.74389518, 0.74389518, 0.74389518,\n",
       "        0.74389518, 0.74389518, 0.74389518, 0.74389518, 0.74389518,\n",
       "        0.74389518, 0.74389518]),\n",
       " 'split3_train_score': array([0.50832342, 0.7039239 , 0.72592152, 0.72592152, 0.72592152,\n",
       "        0.72592152, 0.72592152, 0.72592152, 0.72592152, 0.72592152,\n",
       "        0.72592152, 0.72592152, 0.72592152, 0.72592152, 0.72592152,\n",
       "        0.72592152, 0.53567182, 0.70868014, 0.70868014, 0.70868014,\n",
       "        0.70868014, 0.70868014, 0.70868014, 0.70868014, 0.70868014,\n",
       "        0.70868014, 0.70868014, 0.70868014, 0.70868014, 0.70868014,\n",
       "        0.70868014, 0.70868014]),\n",
       " 'split4_train_score': array([0.46761735, 0.68330362, 0.70350564, 0.70350564, 0.70350564,\n",
       "        0.70350564, 0.70350564, 0.70350564, 0.70350564, 0.70350564,\n",
       "        0.70350564, 0.70350564, 0.70350564, 0.70350564, 0.70350564,\n",
       "        0.70350564, 0.53832442, 0.70944742, 0.70944742, 0.70944742,\n",
       "        0.70944742, 0.70944742, 0.70944742, 0.70944742, 0.70944742,\n",
       "        0.70944742, 0.70944742, 0.70944742, 0.70944742, 0.70944742,\n",
       "        0.70944742, 0.70944742]),\n",
       " 'mean_train_score': array([0.50251742, 0.70048006, 0.71857285, 0.71857285, 0.71857285,\n",
       "        0.71857285, 0.71857285, 0.71857285, 0.71857285, 0.71857285,\n",
       "        0.71857285, 0.71857285, 0.71857285, 0.71857285, 0.71857285,\n",
       "        0.71857285, 0.53881122, 0.71977021, 0.71977021, 0.71977021,\n",
       "        0.71977021, 0.71977021, 0.71977021, 0.71977021, 0.71977021,\n",
       "        0.71977021, 0.71977021, 0.71977021, 0.71977021, 0.71977021,\n",
       "        0.71977021, 0.71977021]),\n",
       " 'std_train_score': array([0.01833865, 0.01563326, 0.0127325 , 0.0127325 , 0.0127325 ,\n",
       "        0.0127325 , 0.0127325 , 0.0127325 , 0.0127325 , 0.0127325 ,\n",
       "        0.0127325 , 0.0127325 , 0.0127325 , 0.0127325 , 0.0127325 ,\n",
       "        0.0127325 , 0.00396445, 0.01278668, 0.01278668, 0.01278668,\n",
       "        0.01278668, 0.01278668, 0.01278668, 0.01278668, 0.01278668,\n",
       "        0.01278668, 0.01278668, 0.01278668, 0.01278668, 0.01278668,\n",
       "        0.01278668, 0.01278668])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Set up the parameter grid to seaerch\n",
    "param_grid ={'criterion': ['gini', \"entropy\"], \\\n",
    "             'max_depth': list(range(3, 50, 3)), \\\n",
    "             'min_samples_split': [200]}\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_tree = GridSearchCV(tree.DecisionTreeClassifier(), \\\n",
    "                                param_grid, cv=cv_folds, verbose = 2, \\\n",
    "                            return_train_score=True)\n",
    "my_tuned_tree.fit(X_train_plus_valid, y_train_plus_valid)\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "display(my_tuned_tree.best_params_)\n",
    "model_tuned_params_list[\"Tuned Decision Tree\"] = my_tuned_tree.best_params_\n",
    "display(my_tuned_tree.best_score_)\n",
    "display(my_tuned_tree.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the performance of the tuned tree on <b>Validation Dataset</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7716666666666666\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.83      0.85        52\n",
      "          1       1.00      0.86      0.93        58\n",
      "          2       0.89      0.61      0.72        69\n",
      "          3       0.53      0.84      0.65        63\n",
      "          4       0.55      0.78      0.64        63\n",
      "          5       0.84      0.85      0.84        54\n",
      "          6       0.59      0.41      0.48        56\n",
      "          7       0.91      0.88      0.90        60\n",
      "          8       0.92      0.82      0.87        73\n",
      "          9       0.92      0.85      0.88        52\n",
      "\n",
      "avg / total       0.80      0.77      0.78       600\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>49</td>\n",
       "      <td>50</td>\n",
       "      <td>47</td>\n",
       "      <td>100</td>\n",
       "      <td>89</td>\n",
       "      <td>55</td>\n",
       "      <td>39</td>\n",
       "      <td>58</td>\n",
       "      <td>65</td>\n",
       "      <td>48</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1   2    3   4   5   6   7   8   9  All\n",
       "True                                                   \n",
       "0          43   0   0    8   0   0   1   0   0   0   52\n",
       "1           0  50   0    6   0   0   2   0   0   0   58\n",
       "2           0   0  42    1  23   0   3   0   0   0   69\n",
       "3           0   0   0   53   7   1   2   0   0   0   63\n",
       "4           0   0   2    5  49   0   6   0   1   0   63\n",
       "5           0   0   0    4   0  46   0   1   1   2   54\n",
       "6           6   0   3   13   8   0  23   0   3   0   56\n",
       "7           0   0   0    0   0   5   0  53   0   2   60\n",
       "8           0   0   0    7   2   1   2   1  60   0   73\n",
       "9           0   0   0    3   0   2   0   3   0  44   52\n",
       "All        49  50  47  100  89  55  39  58  65  48  600"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tuned_tree.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "model_valid_accuracy_comparisons[\"Tuned Decision Tree\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "report = metrics.classification_report(y_valid, y_pred)\n",
    "model_valid_f1_comparisons[\"Tuned Decision Tree\"] = report.split('\\n')[-2].split('      ')[3]\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the performance of the tuned tree on <b> Test Dataset </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6955555555555556\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.67      0.71        90\n",
      "          1       0.94      0.80      0.87       102\n",
      "          2       0.69      0.59      0.63        87\n",
      "          3       0.43      0.86      0.58        76\n",
      "          4       0.53      0.67      0.59        81\n",
      "          5       0.87      0.63      0.73        86\n",
      "          6       0.52      0.35      0.42       104\n",
      "          7       0.88      0.81      0.84        98\n",
      "          8       0.78      0.76      0.77        92\n",
      "          9       0.77      0.89      0.83        84\n",
      "\n",
      "avg / total       0.72      0.70      0.70       900\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>79</td>\n",
       "      <td>87</td>\n",
       "      <td>74</td>\n",
       "      <td>150</td>\n",
       "      <td>102</td>\n",
       "      <td>62</td>\n",
       "      <td>69</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>97</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1   2    3    4   5   6   7   8   9  All\n",
       "True                                                    \n",
       "0          60   0   2   23    1   0   2   0   2   0   90\n",
       "1           0  82   2   15    1   0   2   0   0   0  102\n",
       "2           1   0  51    1   22   0  11   0   1   0   87\n",
       "3           0   1   2   65    3   1   4   0   0   0   76\n",
       "4           0   1   1   13   54   1  10   0   1   0   81\n",
       "5           0   0   0   10    0  54   0   5   8   9   86\n",
       "6          17   1  16   11   16   0  36   0   7   0  104\n",
       "7           0   0   0    1    0   5   0  79   1  12   98\n",
       "8           0   2   0   10    5   0   4   0  70   1   92\n",
       "9           1   0   0    1    0   1   0   6   0  75   84\n",
       "All        79  87  74  150  102  62  69  90  90  97  900"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tuned_tree.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"Tuned Decision Tree\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "report = metrics.classification_report(y_test, y_pred)\n",
    "model_test_f1_comparisons[\"Tuned Decision Tree\"] = report.split('\\n')[-2].split('      ')[3]\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=50, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=10, n_jobs=1, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging_model = ensemble.BaggingClassifier(base_estimator = tree.DecisionTreeClassifier(criterion=\"entropy\", \\\n",
    "                                                                                        min_samples_leaf = 50), \\\n",
    "                                                                                        n_estimators=10)\n",
    "bagging_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the performance of the tuned tree on <b>Validation Dataset</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7566666666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.83      0.82        52\n",
      "          1       1.00      0.86      0.93        58\n",
      "          2       0.80      0.70      0.74        69\n",
      "          3       0.62      0.79      0.69        63\n",
      "          4       0.55      0.67      0.60        63\n",
      "          5       0.78      0.80      0.79        54\n",
      "          6       0.61      0.30      0.40        56\n",
      "          7       0.78      0.88      0.83        60\n",
      "          8       0.80      0.90      0.85        73\n",
      "          9       0.91      0.81      0.86        52\n",
      "\n",
      "avg / total       0.76      0.76      0.75       600\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>53</td>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "      <td>81</td>\n",
       "      <td>77</td>\n",
       "      <td>55</td>\n",
       "      <td>28</td>\n",
       "      <td>68</td>\n",
       "      <td>82</td>\n",
       "      <td>46</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1   2   3   4   5   6   7   8   9  All\n",
       "True                                                  \n",
       "0          43   0   0   8   0   0   0   0   1   0   52\n",
       "1           0  50   0   6   1   0   0   0   1   0   58\n",
       "2           0   0  48   1  15   0   4   0   1   0   69\n",
       "3           1   0   2  50   6   2   0   0   1   1   63\n",
       "4           0   0   5   6  42   0   7   0   3   0   63\n",
       "5           0   0   0   0   0  43   0   6   2   3   54\n",
       "6           9   0   4   8  12   0  17   0   6   0   56\n",
       "7           0   0   0   0   0   7   0  53   0   0   60\n",
       "8           0   0   1   2   1   1   0   2  66   0   73\n",
       "9           0   0   0   0   0   2   0   7   1  42   52\n",
       "All        53  50  60  81  77  55  28  68  82  46  600"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the validation data\n",
    "y_pred = bagging_model.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "model_valid_accuracy_comparisons[\"Bagging\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "\n",
    "report = metrics.classification_report(y_valid, y_pred)\n",
    "model_valid_f1_comparisons[\"Bagging\"] = report.split('\\n')[-2].split('      ')[3]\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the performance of the tuned tree on <b>Test Dataset</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7188888888888889\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.74      0.74        90\n",
      "          1       0.98      0.79      0.88       102\n",
      "          2       0.58      0.66      0.61        87\n",
      "          3       0.56      0.87      0.68        76\n",
      "          4       0.57      0.69      0.62        81\n",
      "          5       0.82      0.73      0.77        86\n",
      "          6       0.63      0.18      0.28       104\n",
      "          7       0.87      0.84      0.85        98\n",
      "          8       0.74      0.92      0.82        92\n",
      "          9       0.76      0.85      0.80        84\n",
      "\n",
      "avg / total       0.73      0.72      0.70       900\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>92</td>\n",
       "      <td>83</td>\n",
       "      <td>99</td>\n",
       "      <td>117</td>\n",
       "      <td>99</td>\n",
       "      <td>77</td>\n",
       "      <td>30</td>\n",
       "      <td>94</td>\n",
       "      <td>115</td>\n",
       "      <td>94</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1   2    3   4   5   6   7    8   9  All\n",
       "True                                                    \n",
       "0          67   0   4   15   0   0   0   0    4   0   90\n",
       "1           0  81   4   15   0   1   1   0    0   0  102\n",
       "2           1   1  57    0  20   0   6   0    2   0   87\n",
       "3           1   0   2   66   5   1   0   0    1   0   76\n",
       "4           1   1   6   12  56   0   4   0    1   0   81\n",
       "5           0   0   0    0   0  63   0   6    6  11   86\n",
       "6          21   0  24    7  17   0  19   0   16   0  104\n",
       "7           0   0   0    0   0   6   0  82    0  10   98\n",
       "8           0   0   2    2   1   0   0   0   85   2   92\n",
       "9           1   0   0    0   0   6   0   6    0  71   84\n",
       "All        92  83  99  117  99  77  30  94  115  94  900"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = bagging_model.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"Bagging\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "report = metrics.classification_report(y_test, y_pred)\n",
    "model_test_f1_comparisons[\"Bagging\"] = report.split('\\n')[-2].split('      ')[3]\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose parameters using a grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=5 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=5, total=   0.8s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=5, total=   0.8s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=5 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=5, total=   0.8s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=5 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=5, total=   0.8s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=5 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=5, total=   0.8s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=10 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=10, total=   1.6s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=10 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=10, total=   1.6s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=10 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=10, total=   1.6s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=10 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=10, total=   1.6s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=10 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=10, total=   1.6s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=15 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=15, total=   2.4s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=15 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=15, total=   2.4s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=15 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=15, total=   2.4s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=15 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=15, total=   2.5s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=15 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=15, total=   2.5s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=20 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=20, total=   3.3s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=20 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=20, total=   3.4s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=20 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=20, total=   3.4s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=20 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=20, total=   3.4s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=20 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=20, total=   3.3s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=25 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=25, total=   4.1s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=25 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=25, total=   4.2s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=25 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=25, total=   4.1s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=25 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=25, total=   4.2s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=25 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=25, total=   4.1s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=30 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=30, total=   5.0s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=30 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=30, total=   5.1s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=30 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=30, total=   5.1s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=30 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=30, total=   5.1s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=30 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=30, total=   5.1s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=35 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=35, total=   5.9s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=35 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=35, total=   6.0s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=35 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=35, total=   6.0s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=35 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=35, total=   5.9s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=35 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=35, total=   5.8s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=40 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=40, total=   6.5s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=40 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=40, total=   6.7s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=40 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=40, total=   6.8s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=40 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=40, total=   6.9s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=40 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=40, total=   6.8s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=45 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=45, total=   7.6s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=45 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=45, total=   7.3s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=45 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=45, total=   7.2s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=45 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=45, total=   7.5s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=45 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=45, total=   7.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:  3.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=50, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'n_estimators': 45}\n",
      "0.7390476190476191\n"
     ]
    }
   ],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid = [\n",
    " {'n_estimators': list(range(5, 50, 5)),\n",
    "  'base_estimator': [tree.DecisionTreeClassifier(criterion=\"entropy\", max_depth = 6, min_samples_leaf = 50)]}\n",
    "]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_bagging_model = GridSearchCV(ensemble.BaggingClassifier(), param_grid, cv=cv_folds, verbose = 2)\n",
    "my_tuned_bagging_model.fit(X_train_plus_valid, y_train_plus_valid)\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(my_tuned_bagging_model.best_params_)\n",
    "model_tuned_params_list[\"Tuned Bagging\"] = my_tuned_bagging_model.best_params_\n",
    "print(my_tuned_bagging_model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the performance of the tuned tree on <b>Validation Dataset</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8066666666666666\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.85      0.82        52\n",
      "          1       1.00      0.86      0.93        58\n",
      "          2       0.77      0.71      0.74        69\n",
      "          3       0.69      0.87      0.77        63\n",
      "          4       0.69      0.79      0.74        63\n",
      "          5       0.85      0.87      0.86        54\n",
      "          6       0.80      0.43      0.56        56\n",
      "          7       0.82      0.90      0.86        60\n",
      "          8       0.83      0.93      0.88        73\n",
      "          9       0.93      0.83      0.88        52\n",
      "\n",
      "avg / total       0.81      0.81      0.80       600\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>55</td>\n",
       "      <td>50</td>\n",
       "      <td>64</td>\n",
       "      <td>80</td>\n",
       "      <td>72</td>\n",
       "      <td>55</td>\n",
       "      <td>30</td>\n",
       "      <td>66</td>\n",
       "      <td>82</td>\n",
       "      <td>46</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1   2   3   4   5   6   7   8   9  All\n",
       "True                                                  \n",
       "0          44   0   1   6   0   0   0   0   1   0   52\n",
       "1           0  50   1   6   0   0   0   0   1   0   58\n",
       "2           1   0  49   1  14   0   4   0   0   0   69\n",
       "3           1   0   2  55   2   1   0   0   2   0   63\n",
       "4           0   0   5   5  50   0   2   0   1   0   63\n",
       "5           0   0   0   0   0  47   0   4   1   2   54\n",
       "6           9   0   5   7   5   0  24   0   6   0   56\n",
       "7           0   0   0   0   0   5   0  54   0   1   60\n",
       "8           0   0   1   0   1   1   0   2  68   0   73\n",
       "9           0   0   0   0   0   1   0   6   2  43   52\n",
       "All        55  50  64  80  72  55  30  66  82  46  600"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tuned_bagging_model.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "model_valid_accuracy_comparisons[\"Tuned Bagging\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "report = metrics.classification_report(y_valid, y_pred)\n",
    "model_valid_f1_comparisons[\"Tuned Bagging\"] = report.split('\\n')[-2].split('      ')[3]\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the performance of the tuned tree on <b>Test Dataset</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7188888888888889\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.73      0.72        90\n",
      "          1       0.98      0.79      0.88       102\n",
      "          2       0.57      0.66      0.61        87\n",
      "          3       0.56      0.88      0.68        76\n",
      "          4       0.57      0.64      0.60        81\n",
      "          5       0.82      0.72      0.77        86\n",
      "          6       0.76      0.25      0.38       104\n",
      "          7       0.89      0.83      0.86        98\n",
      "          8       0.73      0.88      0.80        92\n",
      "          9       0.75      0.88      0.81        84\n",
      "\n",
      "avg / total       0.74      0.72      0.71       900\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>94</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>120</td>\n",
       "      <td>92</td>\n",
       "      <td>76</td>\n",
       "      <td>34</td>\n",
       "      <td>91</td>\n",
       "      <td>111</td>\n",
       "      <td>99</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1    2    3   4   5   6   7    8   9  All\n",
       "True                                                     \n",
       "0          66   0    3   16   0   0   0   0    5   0   90\n",
       "1           0  81    5   15   0   1   0   0    0   0  102\n",
       "2           4   0   57    0  24   0   1   0    1   0   87\n",
       "3           1   0    3   67   1   1   2   0    1   0   76\n",
       "4           1   1    7   13  52   0   4   0    3   0   81\n",
       "5           0   0    0    0   0  62   0   6    6  12   86\n",
       "6          21   0   23    7  13   0  26   0   14   0  104\n",
       "7           0   0    0    0   0   4   0  81    0  13   98\n",
       "8           1   1    2    2   2   3   0   0   81   0   92\n",
       "9           0   0    0    0   0   5   1   4    0  74   84\n",
       "All        94  83  100  120  92  76  34  91  111  99  900"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tuned_bagging_model.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"Tuned Bagging\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "report = metrics.classification_report(y_test, y_pred)\n",
    "model_test_f1_comparisons[\"Tuned Bagging\"] = report.split('\\n')[-2].split('      ')[3]\n",
    "\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Summary of results</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Accuracy-Validation Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>StackedEnsembleClassifier LogisticRegression</td>\n",
       "      <td>0.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>StackedEnsembleHoldOutClassifier LogisticRegre...</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>StackedEnsembleKFoldClassifier LogisticRegression</td>\n",
       "      <td>0.811667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>StackedEnsembleClassifier DecisionTree</td>\n",
       "      <td>0.776667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>StackedEnsembleHoldOutClassifier DecisionTree</td>\n",
       "      <td>0.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>StackedEnsembleKFoldClassifier DecisionTree</td>\n",
       "      <td>0.746667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Single Decision Tree</td>\n",
       "      <td>0.711667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tuned Decision Tree</td>\n",
       "      <td>0.771667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bagging</td>\n",
       "      <td>0.756667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tuned Bagging</td>\n",
       "      <td>0.806667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Model Name  Accuracy-Validation Data\n",
       "0       StackedEnsembleClassifier LogisticRegression                  0.810000\n",
       "1  StackedEnsembleHoldOutClassifier LogisticRegre...                  0.800000\n",
       "2  StackedEnsembleKFoldClassifier LogisticRegression                  0.811667\n",
       "3             StackedEnsembleClassifier DecisionTree                  0.776667\n",
       "4      StackedEnsembleHoldOutClassifier DecisionTree                  0.766667\n",
       "5        StackedEnsembleKFoldClassifier DecisionTree                  0.746667\n",
       "6                               Single Decision Tree                  0.711667\n",
       "7                                Tuned Decision Tree                  0.771667\n",
       "8                                            Bagging                  0.756667\n",
       "9                                      Tuned Bagging                  0.806667"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(model_valid_accuracy_comparisons.items()), columns=['Model Name', 'Accuracy-Validation Data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Accuracy of Test Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>StackedEnsembleClassifier LogisticRegression</td>\n",
       "      <td>0.804444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>StackedEnsembleHoldOutClassifier LogisticRegre...</td>\n",
       "      <td>0.803333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>StackedEnsembleKFoldClassifier LogisticRegression</td>\n",
       "      <td>0.797778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>StackedEnsembleClassifier DecisionTree</td>\n",
       "      <td>0.775556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>StackedEnsembleHoldOutClassifier DecisionTree</td>\n",
       "      <td>0.757778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>StackedEnsembleKFoldClassifier DecisionTree</td>\n",
       "      <td>0.745556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.671111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tuned Decision Tree</td>\n",
       "      <td>0.695556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bagging</td>\n",
       "      <td>0.718889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tuned Bagging</td>\n",
       "      <td>0.718889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Model Name  Accuracy of Test Data\n",
       "0       StackedEnsembleClassifier LogisticRegression               0.804444\n",
       "1  StackedEnsembleHoldOutClassifier LogisticRegre...               0.803333\n",
       "2  StackedEnsembleKFoldClassifier LogisticRegression               0.797778\n",
       "3             StackedEnsembleClassifier DecisionTree               0.775556\n",
       "4      StackedEnsembleHoldOutClassifier DecisionTree               0.757778\n",
       "5        StackedEnsembleKFoldClassifier DecisionTree               0.745556\n",
       "6                                      Decision Tree               0.671111\n",
       "7                                Tuned Decision Tree               0.695556\n",
       "8                                            Bagging               0.718889\n",
       "9                                      Tuned Bagging               0.718889"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(model_test_accuracy_comparisons.items()), columns=['Model Name', 'Accuracy of Test Data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Average F1 score of Validation Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>StackedEnsembleClassifier LogisticRegression</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>StackedEnsembleHoldOutClassifier LogisticRegre...</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>StackedEnsembleKFoldClassifier LogisticRegression</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>StackedEnsembleClassifier DecisionTree</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>StackedEnsembleHoldOutClassifier DecisionTree</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>StackedEnsembleKFoldClassifier DecisionTree</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Single Decision Tree</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tuned Decision Tree</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bagging</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tuned Bagging</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Model Name  \\\n",
       "0       StackedEnsembleClassifier LogisticRegression   \n",
       "1  StackedEnsembleHoldOutClassifier LogisticRegre...   \n",
       "2  StackedEnsembleKFoldClassifier LogisticRegression   \n",
       "3             StackedEnsembleClassifier DecisionTree   \n",
       "4      StackedEnsembleHoldOutClassifier DecisionTree   \n",
       "5        StackedEnsembleKFoldClassifier DecisionTree   \n",
       "6                               Single Decision Tree   \n",
       "7                                Tuned Decision Tree   \n",
       "8                                            Bagging   \n",
       "9                                      Tuned Bagging   \n",
       "\n",
       "  Average F1 score of Validation Data  \n",
       "0                                0.81  \n",
       "1                                0.80  \n",
       "2                                0.81  \n",
       "3                                0.78  \n",
       "4                                0.77  \n",
       "5                                0.74  \n",
       "6                                0.71  \n",
       "7                                0.78  \n",
       "8                                0.75  \n",
       "9                                0.80  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(model_valid_f1_comparisons.items()), columns=['Model Name', 'Average F1 score of Validation Data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Average F1 score of Test Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>StackedEnsembleClassifier LogisticRegression</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>StackedEnsembleHoldOutClassifier LogisticRegre...</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>StackedEnsembleKFoldClassifier LogisticRegression</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>StackedEnsembleClassifier DecisionTree</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>StackedEnsembleHoldOutClassifier DecisionTree</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>StackedEnsembleKFoldClassifier DecisionTree</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tuned Decision Tree</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bagging</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tuned Bagging</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Model Name  \\\n",
       "0       StackedEnsembleClassifier LogisticRegression   \n",
       "1  StackedEnsembleHoldOutClassifier LogisticRegre...   \n",
       "2  StackedEnsembleKFoldClassifier LogisticRegression   \n",
       "3             StackedEnsembleClassifier DecisionTree   \n",
       "4      StackedEnsembleHoldOutClassifier DecisionTree   \n",
       "5        StackedEnsembleKFoldClassifier DecisionTree   \n",
       "6                                      Decision Tree   \n",
       "7                                Tuned Decision Tree   \n",
       "8                                            Bagging   \n",
       "9                                      Tuned Bagging   \n",
       "\n",
       "  Average F1 score of Test Data  \n",
       "0                          0.80  \n",
       "1                          0.80  \n",
       "2                          0.79  \n",
       "3                          0.78  \n",
       "4                          0.76  \n",
       "5                          0.74  \n",
       "6                          0.66  \n",
       "7                          0.70  \n",
       "8                          0.70  \n",
       "9                          0.71  "
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(model_test_f1_comparisons.items()), columns=['Model Name', 'Average F1 score of Test Data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Observation</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the results that stacked ensemble models are better than single decision tree or an ensemble based on bagging. Single Decision Tree is giving us lowest accuracy even after tuning the model. Bagging technique is also not helping us to get high accuracy or F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Implement the StackedEnsembleOneVsOne Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have implement StackedEnsembleOneVsOne using two approaches-\n",
    "\n",
    "1) By using <b> entire training data </b> for generating predictions from the trained base classifiers that forms the training dataset for the stack layer. <br>\n",
    "2) <b>Hold out approach </b> - In this we are dividing dataset into training and test set. Then using training dataset to train the model for respective binary classifers and test dataset to generate stack layer training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Approach 1</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackedEnsembleOneVsOne(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    \"\"\"An ensemble classifier that uses homogeneous models at the base layer and a aggregation model at the aggregation layer.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    base_estimator_type: string, by default decision tree \n",
    "           Since base layer is homogenous, so we need to specify only one type of classifier. Supported types are\n",
    "        - \"svm\" Support Vector Machine implemented by sklearn.svm.SVC\n",
    "        - \"logreg\" Logistic Regression implemented by sklearn.linear_models.LogisticRegression\n",
    "        - \"knn\" k Nearest Neighbour implemented by sklearn.neighbors.KNeighborsClassifier\n",
    "        - \"tree\" Decision Tree implemented by sklearn.tree.DecisionTreeClassifier\n",
    "        - \"randomforest\" RandomForest implemented by sklearn.tree.RandomForestClassifier    \n",
    "    stack_layer_classifier: string, optional (default = \"logreg')\n",
    "        The classifier type used at the stack layer. The same classifier types as are supported at the base layer are supported        \n",
    "    training_folds: int, optional (default = 4)\n",
    "        How many folds will be used to generate the training set for the stacked layer\n",
    "        \n",
    "    Attributes\n",
    "    ----------\n",
    "    classes_ : array of shape = [n_classes] \n",
    "        The classes labels (single output problem).\n",
    "\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The default values for most base learners are used.\n",
    "\n",
    "    See also\n",
    "    --------\n",
    "    \n",
    "    ----------\n",
    "    .. [1]  van der Laan, M., Polley, E. & Hubbard, A. (2007). \n",
    "            Super Learner. Statistical Applications in Genetics \n",
    "            and Molecular Biology, 6(1) \n",
    "            doi:10.2202/1544-6115.1309\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from sklearn.datasets import load_iris\n",
    "    >>> from sklearn.model_selection import cross_val_score\n",
    "    >>> clf = StackedEnsembleClassifier()\n",
    "    >>> iris = load_iris()\n",
    "    >>> cross_val_score(clf, iris.data, iris.target, cv=10)\n",
    "\n",
    "    \"\"\"\n",
    "    # Constructor for the classifier object\n",
    "    def __init__(self, base_estimator_type = \"tree\", stack_layer_classifier_type = \"logreg\"):\n",
    "        \"\"\"Setup a SuperLearner classifier .\n",
    "        Parameters\n",
    "        ----------\n",
    "        base_estimator_types: The types of classifiers to include at the base layer\n",
    "        base_estimator_duplicates: The number of duplicates of each type of classiifer to include\n",
    "        stack_layer_classifier_type: The type of classifier to include at the stack layer \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Nothing\n",
    "        \"\"\"     \n",
    "\n",
    "        # Initialise class variabels\n",
    "        self.base_estimator_type = base_estimator_type\n",
    "        self.stack_layer_classifier_type = stack_layer_classifier_type\n",
    "\n",
    "    # The fit function to train a classifier\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Build a SuperLearner classifier from the training set (X, y).\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape = [n_samples, n_features]\n",
    "            The training input samples. \n",
    "        y : array-like, shape = [n_samples] \n",
    "            The target values (class labels) as integers or strings.\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "        \"\"\"     \n",
    "        # Check that X and y have correct shape\n",
    "        X, y = check_X_y(X, y)\n",
    "        # Store the classes seen during fit\n",
    "        self.classes_ = unique_labels(y) \n",
    "        \n",
    "        #finding the pairs of target class. For example- of we have three classes 0,1,2.\n",
    "        # pair_target_class will generate- [[0, 1], [0, 2], [1, 2]]\n",
    "        pair_target_class = [];   \n",
    "        pair_target_class=[list(t) for t in itertools.combinations(self.classes_,2)]  \n",
    " \n",
    "        ########################\n",
    "        # LEVEL 0\n",
    "        ########################\n",
    "        \n",
    "        # Set up the base classifeirs in the ensemble\n",
    "        self.classifiers_ = list()\n",
    "        \n",
    "        for i in range(0, len(pair_target_class)):      \n",
    "                c = create_classifier(self.base_estimator_type, tree_min_samples_split=math.ceil(len(X)*0.05))\n",
    "                self.classifiers_.append(c)\n",
    "        \n",
    "        # Store the number of classifers in the ensemble\n",
    "        self.n_estimators_ = len(self.classifiers_)\n",
    "        \n",
    "        # Set up empty arrays to hold stack layer training data\n",
    "        self.X_stack_train = None #(dtype = float)\n",
    "        self.y_stack_train = y\n",
    "        \n",
    "        counter=0;\n",
    "        \n",
    "        # Train each base calssifier and generate the stack layer training dataset\n",
    "        for classifier in self.classifiers_:\n",
    "\n",
    "            # Extract the data which belongs to a particular pair of target class   \n",
    "            X_train_sample = X[np.isin(y,pair_target_class[counter])]\n",
    "            y_train_sample = y[np.isin(y,pair_target_class[counter])]\n",
    "            \n",
    "            # Train a base classifier on those particular pair of class label\n",
    "            classifier.fit(X_train_sample, y_train_sample)\n",
    "            \n",
    "            # Make predictions for all instances in the test set\n",
    "            y_pred = classifier.predict_proba(X)\n",
    "    \n",
    "            #increment the counter. This keeps track of the pairs in the list of target clas pairs\n",
    "            counter=counter+1\n",
    "\n",
    "            # Append the predictions ot the stack layer traing set (a bit of hacking here!)\n",
    "            try:\n",
    "                self.X_stack_train = np.c_[self.X_stack_train, y_pred]                \n",
    "            except ValueError:\n",
    "                self.X_stack_train = y_pred\n",
    "        \n",
    "        \n",
    "        ########################\n",
    "        # LEVEL 1\n",
    "        ########################\n",
    "        \n",
    "        # Create the stack layer classifier\n",
    "        self.stack_layer_classifier_ = create_classifier(self.stack_layer_classifier_type, tree_min_samples_split=math.ceil(len(X)*0.05))\n",
    "\n",
    "        # Train the stack layer using the newly created dataset\n",
    "        self.stack_layer_classifier_.fit(self.X_stack_train, self.y_stack_train)\n",
    "            \n",
    "        # Return the classifier\n",
    "        return self\n",
    "\n",
    "    # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels of the input samples X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like matrix of shape = [n_samples, n_features]\n",
    "            The input samples. \n",
    "        Returns\n",
    "        -------\n",
    "        p : array of shape = [n_samples, ].\n",
    "            The predicted class labels of the input samples. \n",
    "        \"\"\"\n",
    "        \n",
    "        # Check is fit had been called by confirming that the teamplates_ dictiponary has been set up\n",
    "        check_is_fitted(self, ['stack_layer_classifier_'])\n",
    "\n",
    "        # Check that the input features match the type and shape of the training features\n",
    "        X = check_array(X)\n",
    "   \n",
    "        X_stack_queries = None\n",
    "              \n",
    "        # Make a prediction with each base classifier and assemble the stack layer query\n",
    "        for classifier in self.classifiers_:\n",
    "            \n",
    "            y_pred = classifier.predict_proba(X)            \n",
    "            try:\n",
    "                X_stack_queries = np.c_[X_stack_queries, y_pred]\n",
    "            except ValueError:\n",
    "                X_stack_queries = y_pred\n",
    "        \n",
    "        # Return the prediction made by the stack layer classifier\n",
    "        return self.stack_layer_classifier_.predict(X_stack_queries)\n",
    "    \n",
    "    # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict class probabilities of the input samples X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like matrix of shape = [n_samples, n_features]\n",
    "            The input samples. \n",
    "        Returns\n",
    "        -------\n",
    "        p : array of shape = [n_samples, n_labels].\n",
    "            The predicted class label probabilities of the input samples. \n",
    "        \"\"\"\n",
    "        # Check is fit had been called by confirming that the teamplates_ dictiponary has been set up\n",
    "        check_is_fitted(self, ['stack_layer_classifier_'])\n",
    "\n",
    "        # Check that the input features match the type and shape of the training features\n",
    "        X = check_array(X)\n",
    "        \n",
    "        X_stack_queries = None\n",
    "        \n",
    "        # Make a prediction with each base classifier\n",
    "        for classifier in self.classifiers_:\n",
    "            \n",
    "            y_pred = classifier.predict_proba(X)\n",
    "                \n",
    "            try:\n",
    "                X_stack_queries = np.c_[X_stack_queries, y_pred]\n",
    "            except ValueError:\n",
    "                X_stack_queries = y_pred\n",
    "\n",
    "        # Return the prediction made by the stack layer classifier        \n",
    "        return self.stack_layer_classifier_.predict_proba(X_stack_queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Approach 2</b> - Using Hold out dataset to generate stack layer training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackedEnsembleOneVsOneHoldOutApproach(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    \"\"\"An ensemble classifier that uses homogeneous models at the base layer and a aggregation model at the aggregation layer.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    base_estimator_type: string, by default decision tree \n",
    "           Since base layer is homogenous, so we need to specify only one type of classifier. Supported types are\n",
    "        - \"svm\" Support Vector Machine implemented by sklearn.svm.SVC\n",
    "        - \"logreg\" Logistic Regression implemented by sklearn.linear_models.LogisticRegression\n",
    "        - \"knn\" k Nearest Neighbour implemented by sklearn.neighbors.KNeighborsClassifier\n",
    "        - \"tree\" Decision Tree implemented by sklearn.tree.DecisionTreeClassifier\n",
    "        - \"randomforest\" RandomForest implemented by sklearn.tree.RandomForestClassifier    \n",
    "    stack_layer_classifier: string, optional (default = \"logreg')\n",
    "        The classifier type used at the stack layer. The same classifier types as are supported at the base layer are supported        \n",
    "    training_folds: int, optional (default = 4)\n",
    "        How many folds will be used to generate the training set for the stacked layer\n",
    "        \n",
    "    Attributes\n",
    "    ----------\n",
    "    classes_ : array of shape = [n_classes] \n",
    "        The classes labels (single output problem).\n",
    "\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The default values for most base learners are used.\n",
    "\n",
    "    See also\n",
    "    --------\n",
    "    \n",
    "    ----------\n",
    "    .. [1]  van der Laan, M., Polley, E. & Hubbard, A. (2007). \n",
    "            Super Learner. Statistical Applications in Genetics \n",
    "            and Molecular Biology, 6(1) \n",
    "            doi:10.2202/1544-6115.1309\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from sklearn.datasets import load_iris\n",
    "    >>> from sklearn.model_selection import cross_val_score\n",
    "    >>> clf = StackedEnsembleClassifier()\n",
    "    >>> iris = load_iris()\n",
    "    >>> cross_val_score(clf, iris.data, iris.target, cv=10)\n",
    "\n",
    "    \"\"\"\n",
    "    # Constructor for the classifier object\n",
    "    def __init__(self, base_estimator_type = \"tree\", stack_layer_classifier_type = \"logreg\"):\n",
    "        \"\"\"Setup a SuperLearner classifier .\n",
    "        Parameters\n",
    "        ----------\n",
    "        base_estimator_types: The types of classifiers to include at the base layer\n",
    "        base_estimator_duplicates: The number of duplicates of each type of classiifer to include\n",
    "        stack_layer_classifier_type: The type of classifier to include at the stack layer \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Nothing\n",
    "        \"\"\"     \n",
    "\n",
    "        # Initialise class variabels\n",
    "        self.base_estimator_type = base_estimator_type\n",
    "        self.stack_layer_classifier_type = stack_layer_classifier_type\n",
    "\n",
    "    # The fit function to train a classifier\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Build a SuperLearner classifier from the training set (X, y).\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape = [n_samples, n_features]\n",
    "            The training input samples. \n",
    "        y : array-like, shape = [n_samples] \n",
    "            The target values (class labels) as integers or strings.\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "        \"\"\"     \n",
    "        # Check that X and y have correct shape\n",
    "        X, y = check_X_y(X, y)\n",
    "        # Store the classes seen during fit\n",
    "        self.classes_ = unique_labels(y) \n",
    "        \n",
    "        #finding the pairs of target class. For example- of we have three classes 0,1,2.\n",
    "        # pair_target_class will generate- [[0, 1], [0, 2], [1, 2]]\n",
    "        pair_target_class = [];   \n",
    "        pair_target_class=[list(t) for t in itertools.combinations(self.classes_,2)]  \n",
    " \n",
    "        ########################\n",
    "        # LEVEL 0\n",
    "        ########################\n",
    "        \n",
    "        # Set up the base classifeirs in the ensemble\n",
    "        self.classifiers_ = list()\n",
    "        \n",
    "        for i in range(0, len(pair_target_class)):      \n",
    "                c = create_classifier(self.base_estimator_type, tree_min_samples_split=math.ceil(len(X)*0.05))\n",
    "                self.classifiers_.append(c)\n",
    "        \n",
    "        # Store the number of classifers in the ensemble\n",
    "        self.n_estimators_ = len(self.classifiers_)\n",
    "    \n",
    "        \n",
    "        #Splitting the dataset into training and test. Training set is used to train the model and test set is used generate\n",
    "        # the stack layer training data\n",
    "        X_train, X_test, y_train, y_test \\\n",
    "          = train_test_split(X, y, random_state=0, \\\n",
    "                                    train_size = 0.7)\n",
    "        \n",
    "        # Set up empty arrays to hold stack layer training data\n",
    "        self.X_stack_train = None #(dtype = float)\n",
    "        self.y_stack_train = y_test\n",
    "        \n",
    "        counter=0;\n",
    "        \n",
    "        # Train each base calssifier and generate the stack layer training dataset\n",
    "        for classifier in self.classifiers_:\n",
    "\n",
    "            # Extract the data which belongs to a particular pair of target class   \n",
    "            X_train_sample = X_train[np.isin(y_train,pair_target_class[counter])]\n",
    "            y_train_sample = y_train[np.isin(y_train,pair_target_class[counter])]\n",
    "            \n",
    "            # Train a base classifier on those particular pair of class label\n",
    "            classifier.fit(X_train_sample, y_train_sample)\n",
    "            \n",
    "            # Make predictions for all instances in the test set\n",
    "            y_pred = classifier.predict_proba(X_test)\n",
    "    \n",
    "            #increment the counter. This keeps track of the pairs in the list of target clas pairs\n",
    "            counter=counter+1\n",
    "\n",
    "            # Append the predictions ot the stack layer traing set (a bit of hacking here!)\n",
    "            try:\n",
    "                self.X_stack_train = np.c_[self.X_stack_train, y_pred]                \n",
    "            except ValueError:\n",
    "                self.X_stack_train = y_pred\n",
    "        \n",
    "        \n",
    "        ########################\n",
    "        # LEVEL 1\n",
    "        ########################\n",
    "        \n",
    "        # Create the stack layer classifier\n",
    "        self.stack_layer_classifier_ = create_classifier(self.stack_layer_classifier_type, tree_min_samples_split=math.ceil(len(X)*0.05))\n",
    "\n",
    "        # Train the stack layer using the newly created dataset\n",
    "        self.stack_layer_classifier_.fit(self.X_stack_train, self.y_stack_train)\n",
    "            \n",
    "        # Return the classifier\n",
    "        return self\n",
    "\n",
    "    # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels of the input samples X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like matrix of shape = [n_samples, n_features]\n",
    "            The input samples. \n",
    "        Returns\n",
    "        -------\n",
    "        p : array of shape = [n_samples, ].\n",
    "            The predicted class labels of the input samples. \n",
    "        \"\"\"\n",
    "        \n",
    "        # Check is fit had been called by confirming that the teamplates_ dictiponary has been set up\n",
    "        check_is_fitted(self, ['stack_layer_classifier_'])\n",
    "\n",
    "        # Check that the input features match the type and shape of the training features\n",
    "        X = check_array(X)\n",
    "   \n",
    "        X_stack_queries = None\n",
    "              \n",
    "        # Make a prediction with each base classifier and assemble the stack layer query\n",
    "        for classifier in self.classifiers_:\n",
    "            \n",
    "            y_pred = classifier.predict_proba(X)            \n",
    "            try:\n",
    "                X_stack_queries = np.c_[X_stack_queries, y_pred]\n",
    "            except ValueError:\n",
    "                X_stack_queries = y_pred\n",
    "        \n",
    "        # Return the prediction made by the stack layer classifier\n",
    "        return self.stack_layer_classifier_.predict(X_stack_queries)\n",
    "    \n",
    "    # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict class probabilities of the input samples X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like matrix of shape = [n_samples, n_features]\n",
    "            The input samples. \n",
    "        Returns\n",
    "        -------\n",
    "        p : array of shape = [n_samples, n_labels].\n",
    "            The predicted class label probabilities of the input samples. \n",
    "        \"\"\"\n",
    "        # Check is fit had been called by confirming that the teamplates_ dictiponary has been set up\n",
    "        check_is_fitted(self, ['stack_layer_classifier_'])\n",
    "\n",
    "        # Check that the input features match the type and shape of the training features\n",
    "        X = check_array(X)\n",
    "        \n",
    "        X_stack_queries = None\n",
    "        \n",
    "        # Make a prediction with each base classifier\n",
    "        for classifier in self.classifiers_:\n",
    "            \n",
    "            y_pred = classifier.predict_proba(X)\n",
    "                \n",
    "            try:\n",
    "                X_stack_queries = np.c_[X_stack_queries, y_pred]\n",
    "            except ValueError:\n",
    "                X_stack_queries = y_pred\n",
    "\n",
    "        # Return the prediction made by the stack layer classifier        \n",
    "        return self.stack_layer_classifier_.predict_proba(X_stack_queries)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6 Evaluate the Performance of the StackedEnsembleCalassifierOneVsOne Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating Approach 1 where we can using whole training dataset to generate stack layer training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackedEnsembleOneVsOne(base_estimator_type='logreg',\n",
       "            stack_layer_classifier_type='logreg')"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stackedEnsembleOneVsOneModel = StackedEnsembleOneVsOne(base_estimator_type =\"logreg\", \\\n",
    "                                                       stack_layer_classifier_type = \"logreg\")\n",
    "stackedEnsembleOneVsOneModel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the performance of the StackedEnsembleClassifierOneVsOne on the <b>validation set</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8216666666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.88      0.84        52\n",
      "          1       0.98      0.95      0.96        58\n",
      "          2       0.70      0.72      0.71        69\n",
      "          3       0.79      0.86      0.82        63\n",
      "          4       0.70      0.63      0.67        63\n",
      "          5       0.98      0.89      0.93        54\n",
      "          6       0.59      0.54      0.56        56\n",
      "          7       0.85      0.92      0.88        60\n",
      "          8       0.93      0.93      0.93        73\n",
      "          9       0.89      0.90      0.90        52\n",
      "\n",
      "avg / total       0.82      0.82      0.82       600\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>57</td>\n",
       "      <td>56</td>\n",
       "      <td>71</td>\n",
       "      <td>68</td>\n",
       "      <td>57</td>\n",
       "      <td>49</td>\n",
       "      <td>51</td>\n",
       "      <td>65</td>\n",
       "      <td>73</td>\n",
       "      <td>53</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1   2   3   4   5   6   7   8   9  All\n",
       "True                                                  \n",
       "0          46   0   2   3   0   0   1   0   0   0   52\n",
       "1           0  55   1   1   0   0   0   0   1   0   58\n",
       "2           0   0  50   1  11   0   7   0   0   0   69\n",
       "3           3   1   1  54   4   0   0   0   0   0   63\n",
       "4           0   0  10   3  40   0  10   0   0   0   63\n",
       "5           0   0   0   0   0  48   0   4   0   2   54\n",
       "6           8   0   7   5   2   0  30   0   4   0   56\n",
       "7           0   0   0   0   0   1   0  55   0   4   60\n",
       "8           0   0   0   1   0   0   3   1  68   0   73\n",
       "9           0   0   0   0   0   0   0   5   0  47   52\n",
       "All        57  56  71  68  57  49  51  65  73  53  600"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = stackedEnsembleOneVsOneModel.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "\n",
    "model_valid_accuracy_comparisons[\"StackedEnsembleOneVsOne\"] = accuracy\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "#To fetch the average F1 score\n",
    "report = metrics.classification_report(y_valid, y_pred)\n",
    "model_valid_f1_comparisons[\"StackedEnsembleOneVsOne\"] = report.split('\\n')[-2].split('      ')[3]\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "display(pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the performance of the StackedEnsembleClassifierOneVsOne on the <b>test set</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8155555555555556\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.71      0.72        90\n",
      "          1       1.00      0.96      0.98       102\n",
      "          2       0.68      0.70      0.69        87\n",
      "          3       0.75      0.89      0.81        76\n",
      "          4       0.71      0.68      0.70        81\n",
      "          5       0.95      0.90      0.92        86\n",
      "          6       0.62      0.54      0.57       104\n",
      "          7       0.91      0.88      0.89        98\n",
      "          8       0.92      0.96      0.94        92\n",
      "          9       0.87      0.96      0.92        84\n",
      "\n",
      "avg / total       0.81      0.82      0.81       900\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>68</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>88</td>\n",
       "      <td>98</td>\n",
       "      <td>90</td>\n",
       "      <td>91</td>\n",
       "      <td>77</td>\n",
       "      <td>81</td>\n",
       "      <td>91</td>\n",
       "      <td>95</td>\n",
       "      <td>96</td>\n",
       "      <td>93</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1   2   3   4   5   6   7   8   9  All\n",
       "True                                                  \n",
       "0          64   0   1  11   1   1  11   0   1   0   90\n",
       "1           0  98   2   0   0   0   2   0   0   0  102\n",
       "2           5   0  61   1   6   0  12   0   2   0   87\n",
       "3           2   0   3  68   3   0   0   0   0   0   76\n",
       "4           1   0   7   9  55   0   9   0   0   0   81\n",
       "5           0   0   0   0   0  77   0   6   0   3   86\n",
       "6          15   0  15   1  12   0  56   0   5   0  104\n",
       "7           0   0   0   0   0   3   0  86   0   9   98\n",
       "8           1   0   1   1   0   0   1   0  88   0   92\n",
       "9           0   0   0   0   0   0   0   3   0  81   84\n",
       "All        88  98  90  91  77  81  91  95  96  93  900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = stackedEnsembleOneVsOneModel.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "model_test_accuracy_comparisons[\"StackedEnsembleOneVsOne\"] = accuracy\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "report = metrics.classification_report(y_test, y_pred)\n",
    "model_test_f1_comparisons[\"StackedEnsembleOneVsOne\"] = report.split('\\n')[-2].split('      ')[3]\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "display(pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Evaluating Approach 2</b> where we can using hold out dataset to generate stack layer training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackedEnsembleOneVsOneHoldOutApproach(base_estimator_type='logreg',\n",
       "                    stack_layer_classifier_type='logreg')"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stackedEnsembleOneVsOneHoldOutApproachModel = StackedEnsembleOneVsOneHoldOutApproach(base_estimator_type =\"logreg\", \\\n",
    "                                                                                stack_layer_classifier_type = \"logreg\")\n",
    "stackedEnsembleOneVsOneHoldOutApproachModel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the performance of the StackedEnsembleClassifierOneVsOne on the <b>validation set</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8033333333333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.79      0.81        52\n",
      "          1       1.00      0.97      0.98        58\n",
      "          2       0.79      0.67      0.72        69\n",
      "          3       0.70      0.89      0.78        63\n",
      "          4       0.71      0.63      0.67        63\n",
      "          5       0.90      0.85      0.88        54\n",
      "          6       0.52      0.55      0.53        56\n",
      "          7       0.80      0.88      0.84        60\n",
      "          8       0.92      0.93      0.93        73\n",
      "          9       0.90      0.87      0.88        52\n",
      "\n",
      "avg / total       0.81      0.80      0.80       600\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>49</td>\n",
       "      <td>56</td>\n",
       "      <td>58</td>\n",
       "      <td>80</td>\n",
       "      <td>56</td>\n",
       "      <td>51</td>\n",
       "      <td>60</td>\n",
       "      <td>66</td>\n",
       "      <td>74</td>\n",
       "      <td>50</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1   2   3   4   5   6   7   8   9  All\n",
       "True                                                  \n",
       "0          41   0   0   7   0   0   4   0   0   0   52\n",
       "1           0  56   1   0   0   0   0   0   1   0   58\n",
       "2           0   0  46   2  12   0   9   0   0   0   69\n",
       "3           2   0   1  56   2   0   2   0   0   0   63\n",
       "4           0   0   4   8  40   0  11   0   0   0   63\n",
       "5           0   0   0   0   0  46   0   7   0   1   54\n",
       "6           6   0   6   6   2   0  31   0   5   0   56\n",
       "7           0   0   0   0   0   3   0  53   0   4   60\n",
       "8           0   0   0   1   0   0   3   1  68   0   73\n",
       "9           0   0   0   0   0   2   0   5   0  45   52\n",
       "All        49  56  58  80  56  51  60  66  74  50  600"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = stackedEnsembleOneVsOneHoldOutApproachModel.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "model_valid_accuracy_comparisons[\"StackedEnsembleOneVsOne HoldOut Approach\"] = accuracy\n",
    "report = metrics.classification_report(y_valid, y_pred)\n",
    "model_valid_f1_comparisons[\"StackedEnsembleOneVsOne HoldOut Approach\"] = report.split('\\n')[-2].split('      ')[3]\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "display(pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the performance of the StackedEnsembleClassifierOneVsOne on the <b>test set</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8177777777777778\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.73      0.77        90\n",
      "          1       0.99      0.95      0.97       102\n",
      "          2       0.69      0.72      0.71        87\n",
      "          3       0.71      0.91      0.80        76\n",
      "          4       0.71      0.70      0.71        81\n",
      "          5       0.92      0.88      0.90        86\n",
      "          6       0.64      0.51      0.57       104\n",
      "          7       0.89      0.87      0.88        98\n",
      "          8       0.91      1.00      0.95        92\n",
      "          9       0.87      0.93      0.90        84\n",
      "\n",
      "avg / total       0.82      0.82      0.81       900\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>81</td>\n",
       "      <td>98</td>\n",
       "      <td>91</td>\n",
       "      <td>97</td>\n",
       "      <td>80</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>96</td>\n",
       "      <td>101</td>\n",
       "      <td>90</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1   2   3   4   5   6   7    8   9  All\n",
       "True                                                   \n",
       "0          66   1   3  13   0   1   5   0    1   0   90\n",
       "1           0  97   2   1   0   0   2   0    0   0  102\n",
       "2           0   0  63   0   9   0  12   0    3   0   87\n",
       "3           2   0   2  69   2   0   1   0    0   0   76\n",
       "4           0   0   4  10  57   0  10   0    0   0   81\n",
       "5           0   0   0   0   0  76   0   7    0   3   86\n",
       "6          13   0  17   4  12   0  53   0    5   0  104\n",
       "7           0   0   0   0   0   4   0  85    0   9   98\n",
       "8           0   0   0   0   0   0   0   0   92   0   92\n",
       "9           0   0   0   0   0   2   0   4    0  78   84\n",
       "All        81  98  91  97  80  83  83  96  101  90  900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = stackedEnsembleOneVsOneHoldOutApproachModel.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "model_test_accuracy_comparisons[\"StackedEnsembleOneVsOne HoldOut Approach\"] = accuracy\n",
    "report = metrics.classification_report(y_test, y_pred)\n",
    "model_test_f1_comparisons[\"StackedEnsembleOneVsOne HoldOut Approach\"] = report.split('\\n')[-2].split('      ')[3]\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "display(pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Accuracy on Validation Data</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Accuracy-Validation Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>StackedEnsembleClassifier LogisticRegression</td>\n",
       "      <td>0.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>StackedEnsembleHoldOutClassifier LogisticRegre...</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>StackedEnsembleKFoldClassifier LogisticRegression</td>\n",
       "      <td>0.811667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>StackedEnsembleClassifier DecisionTree</td>\n",
       "      <td>0.776667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>StackedEnsembleHoldOutClassifier DecisionTree</td>\n",
       "      <td>0.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>StackedEnsembleKFoldClassifier DecisionTree</td>\n",
       "      <td>0.746667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Single Decision Tree</td>\n",
       "      <td>0.711667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tuned Decision Tree</td>\n",
       "      <td>0.771667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bagging</td>\n",
       "      <td>0.756667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tuned Bagging</td>\n",
       "      <td>0.806667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>StackedEnsembleOneVsOne</td>\n",
       "      <td>0.821667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>StackedEnsembleOneVsOne HoldOut Approach</td>\n",
       "      <td>0.803333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Model Name  \\\n",
       "0        StackedEnsembleClassifier LogisticRegression   \n",
       "1   StackedEnsembleHoldOutClassifier LogisticRegre...   \n",
       "2   StackedEnsembleKFoldClassifier LogisticRegression   \n",
       "3              StackedEnsembleClassifier DecisionTree   \n",
       "4       StackedEnsembleHoldOutClassifier DecisionTree   \n",
       "5         StackedEnsembleKFoldClassifier DecisionTree   \n",
       "6                                Single Decision Tree   \n",
       "7                                 Tuned Decision Tree   \n",
       "8                                             Bagging   \n",
       "9                                       Tuned Bagging   \n",
       "10                            StackedEnsembleOneVsOne   \n",
       "11           StackedEnsembleOneVsOne HoldOut Approach   \n",
       "\n",
       "    Accuracy-Validation Data  \n",
       "0                   0.810000  \n",
       "1                   0.800000  \n",
       "2                   0.811667  \n",
       "3                   0.776667  \n",
       "4                   0.766667  \n",
       "5                   0.746667  \n",
       "6                   0.711667  \n",
       "7                   0.771667  \n",
       "8                   0.756667  \n",
       "9                   0.806667  \n",
       "10                  0.821667  \n",
       "11                  0.803333  "
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(model_valid_accuracy_comparisons.items()), columns=['Model Name', 'Accuracy-Validation Data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlim(0, 1.0)\n",
    "_ = plt.barh(range(len(model_valid_accuracy_comparisons)), list(model_valid_accuracy_comparisons.values()), align='center')\n",
    "_= plt.yticks(range(len(model_valid_accuracy_comparisons)), list(model_valid_accuracy_comparisons.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Accuracy on Test Data</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Accuracy of Test Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>StackedEnsembleClassifier LogisticRegression</td>\n",
       "      <td>0.804444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>StackedEnsembleHoldOutClassifier LogisticRegre...</td>\n",
       "      <td>0.803333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>StackedEnsembleKFoldClassifier LogisticRegression</td>\n",
       "      <td>0.797778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>StackedEnsembleClassifier DecisionTree</td>\n",
       "      <td>0.775556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>StackedEnsembleHoldOutClassifier DecisionTree</td>\n",
       "      <td>0.757778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>StackedEnsembleKFoldClassifier DecisionTree</td>\n",
       "      <td>0.745556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.671111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tuned Decision Tree</td>\n",
       "      <td>0.695556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bagging</td>\n",
       "      <td>0.718889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tuned Bagging</td>\n",
       "      <td>0.718889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>StackedEnsembleOneVsOne</td>\n",
       "      <td>0.815556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>StackedEnsembleOneVsOne HoldOut Approach</td>\n",
       "      <td>0.817778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Model Name  Accuracy of Test Data\n",
       "0        StackedEnsembleClassifier LogisticRegression               0.804444\n",
       "1   StackedEnsembleHoldOutClassifier LogisticRegre...               0.803333\n",
       "2   StackedEnsembleKFoldClassifier LogisticRegression               0.797778\n",
       "3              StackedEnsembleClassifier DecisionTree               0.775556\n",
       "4       StackedEnsembleHoldOutClassifier DecisionTree               0.757778\n",
       "5         StackedEnsembleKFoldClassifier DecisionTree               0.745556\n",
       "6                                       Decision Tree               0.671111\n",
       "7                                 Tuned Decision Tree               0.695556\n",
       "8                                             Bagging               0.718889\n",
       "9                                       Tuned Bagging               0.718889\n",
       "10                            StackedEnsembleOneVsOne               0.815556\n",
       "11           StackedEnsembleOneVsOne HoldOut Approach               0.817778"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(model_test_accuracy_comparisons.items()), columns=['Model Name', 'Accuracy of Test Data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlim(0, 1.0)\n",
    "_ = plt.barh(range(len(model_test_accuracy_comparisons)), list(model_test_accuracy_comparisons.values()), align='center')\n",
    "_ = plt.yticks(range(len(model_test_accuracy_comparisons)), list(model_test_accuracy_comparisons.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Average F1 score on Validation Data</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Average F1 score of Validation Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>StackedEnsembleClassifier LogisticRegression</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>StackedEnsembleHoldOutClassifier LogisticRegre...</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>StackedEnsembleKFoldClassifier LogisticRegression</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>StackedEnsembleClassifier DecisionTree</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>StackedEnsembleHoldOutClassifier DecisionTree</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>StackedEnsembleKFoldClassifier DecisionTree</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Single Decision Tree</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tuned Decision Tree</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bagging</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tuned Bagging</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>StackedEnsembleOneVsOne</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>StackedEnsembleOneVsOne HoldOut Approach</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Model Name  \\\n",
       "0        StackedEnsembleClassifier LogisticRegression   \n",
       "1   StackedEnsembleHoldOutClassifier LogisticRegre...   \n",
       "2   StackedEnsembleKFoldClassifier LogisticRegression   \n",
       "3              StackedEnsembleClassifier DecisionTree   \n",
       "4       StackedEnsembleHoldOutClassifier DecisionTree   \n",
       "5         StackedEnsembleKFoldClassifier DecisionTree   \n",
       "6                                Single Decision Tree   \n",
       "7                                 Tuned Decision Tree   \n",
       "8                                             Bagging   \n",
       "9                                       Tuned Bagging   \n",
       "10                            StackedEnsembleOneVsOne   \n",
       "11           StackedEnsembleOneVsOne HoldOut Approach   \n",
       "\n",
       "   Average F1 score of Validation Data  \n",
       "0                                 0.81  \n",
       "1                                 0.80  \n",
       "2                                 0.81  \n",
       "3                                 0.78  \n",
       "4                                 0.77  \n",
       "5                                 0.74  \n",
       "6                                 0.71  \n",
       "7                                 0.78  \n",
       "8                                 0.75  \n",
       "9                                 0.80  \n",
       "10                                0.82  \n",
       "11                                0.80  "
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(model_valid_f1_comparisons.items()), columns=['Model Name', 'Average F1 score of Validation Data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Average F1 score on Test Data</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Average F1 score of Test Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>StackedEnsembleClassifier LogisticRegression</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>StackedEnsembleHoldOutClassifier LogisticRegre...</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>StackedEnsembleKFoldClassifier LogisticRegression</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>StackedEnsembleClassifier DecisionTree</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>StackedEnsembleHoldOutClassifier DecisionTree</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>StackedEnsembleKFoldClassifier DecisionTree</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tuned Decision Tree</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bagging</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tuned Bagging</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>StackedEnsembleOneVsOne</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>StackedEnsembleOneVsOne HoldOut Approach</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Model Name  \\\n",
       "0        StackedEnsembleClassifier LogisticRegression   \n",
       "1   StackedEnsembleHoldOutClassifier LogisticRegre...   \n",
       "2   StackedEnsembleKFoldClassifier LogisticRegression   \n",
       "3              StackedEnsembleClassifier DecisionTree   \n",
       "4       StackedEnsembleHoldOutClassifier DecisionTree   \n",
       "5         StackedEnsembleKFoldClassifier DecisionTree   \n",
       "6                                       Decision Tree   \n",
       "7                                 Tuned Decision Tree   \n",
       "8                                             Bagging   \n",
       "9                                       Tuned Bagging   \n",
       "10                            StackedEnsembleOneVsOne   \n",
       "11           StackedEnsembleOneVsOne HoldOut Approach   \n",
       "\n",
       "   Average F1 score of Test Data  \n",
       "0                           0.80  \n",
       "1                           0.80  \n",
       "2                           0.79  \n",
       "3                           0.78  \n",
       "4                           0.76  \n",
       "5                           0.74  \n",
       "6                           0.66  \n",
       "7                           0.70  \n",
       "8                           0.70  \n",
       "9                           0.71  \n",
       "10                          0.81  \n",
       "11                          0.81  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(model_test_f1_comparisons.items()), columns=['Model Name', 'Average F1 score of Test Data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7 Reflect on the Performance of the Different Models Evaluated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your reflection here (max 300 words)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy and F1 score are used to evaluate the performance of different models. Higher the accuracy or F1 score, better the model. If we look at the above results, <b>StackedEnsembleOneVsOne</b> is giving us <b>highest accuracy</b> and <b>average F1 score</b> on test data than all other models. We are getting better accuracy as each classifier is trained to correctly predict two classes, which makes each base classifier a specialist. Also, it is <b>computationally less expensive</b> than other models as we are training the model only on the basis of two classes at a time. So this reduces the amount of training data, which is needed to train the base classifiers. To avoid over-fitting, I have used StackedEnsembleOneVsOne with Hold Out approach. With both the approaches, I am getting almost similar results. There is very little variation. Also we can see that stacked ensembles work better than single decision tree or even bagging. Using decision tree is computationally less expensive as it requires training a single model but we are not getting good accuracy by using that. So ensembles are better even though its computationally more expensive as we are training multiple models. Also we can see that there is no over-fitting happening in any of the stack ensembles as it is generalizing well on unseen data (test data). In terms of model complexity, it is less complex to understand a single decision tree than bagging or ensemble approach. But since we are not getting good accuracy, we have to consider ensembles. In ensembles, it is easy to understand StackedEnsembleClassifer than StackedEnsembleOneVsOne approach. In OneVsOne approach, we need to filter the data in order to train the binary base model. That's why it's little complicated. Otherwise, it's computationally less expensive than other models. So on the basis of above summary tables, we can say that StackedEnsembleOneVsOne is better than other models when trained and tested on 0.5% data. We can get better results once we train the model using more data.       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
